{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABI - Automated Bot for Inquiries\n",
    "\n",
    "Neste Notebook, temos todo o workflow de construção de nossa solução ao problema proposto pela Olist.\n",
    "\n",
    "Para a solução do problema, propomos o desenvolvimento de um robô que responda às perguntas feitas por potenciais compradores nas páginas do marketplace, e que, além disso, proporcione aos vendedores (ou à Olist) informações relevantes acerca dos tipos e recorrência de perguntas nos anúncios. \n",
    "\n",
    "O nosso robô será responsável por responder de forma rápida e precisa às perguntas dos potenciais compradores, resolvendo, assim, o grande problema de comunicação entre vendedor e potencial comprador, e contribuindo para o aumento na taxa de conversão de venda.\n",
    "\n",
    "A implementação do robô tem duas componentes fundamentais, como explicaremos a seguir através de um exemplo: digamos que um usuário está na página de anúncio de uma cafeteira, e ele faz a seguinte pergunta: \"tem vermelha?\". Ao ler essa pergunta, o robô acionará suas duas componentes, que são:\n",
    "\n",
    "1) A componente inteligente, que é responsável por identificar qual é a intenção da pergunta, apenas ao lê-la. Com a pergunta \"tem vermelha?\", o robô deve ser capaz de identificar que o usuário está querendo saber sobre as cores do produto. Para isso, contaremos com um algoritmo de inteligência artificial, que nada mais é do que um algoritmo de classificação: com base na pergunta, o robô deve ser capaz de, automaticamente, entender qual a intenção da pergunta, isto é, determinar à que classe a pergunta pertence: em nosso exemplo, seria à classe de \"cores\". Para responder, entra a segunda componente:\n",
    "\n",
    "2) A componente de consulta: uma vez entendido sobre o que se trata a pergunta, o robô deve se direcionar ao arquivo de cadastro daquele produto e procurar o atributo correspondente à intenção da pergunta. Isto é, em nosso exemplo, o robô vai no arquivo de cadastro da cafeteira, que deve conter um campo onde estão listadas as cores disponíveis. Ao ler as cores disponíveis, o robô pode então responder ao usuário quais elas são, em uma resposta como: \"Olá! As cores disponíveis são Azul, Preto e Vermelho!\".\n",
    "\n",
    "E, com essas duas componentes, o robô é capaz de responder às perguntas :)\n",
    "\n",
    "Nossa solução propõe o seguinte novo fluxo de perguntas pré-venda, que passa a ter 4 etapas:\n",
    "\n",
    "1) Possível comprador faz uma pergunta sobre determinado produto na página do marketplace;\n",
    "2) O marketplace sinaliza que há uma pergunta sobre determinado produto, e a envia através de uma API para a Olist;\n",
    "3) (Essa é a nova etapa de mossa solução) Nosso algoritmo, embarcado no portal da Olist, receberá a pergunta, a processará, e formulará a resposta adequada, de forma virtualmente instantânea;\n",
    "4) A Olist devolve a pergunta respondida para o Marketplace, através de outra API.\n",
    "\n",
    "Através do fluxo acima, fica claro que nossa solução dispensa qualquer interface gráfica. Como o algoritmo estará embarcado na plataforma da olist, o que importa é seu código fonte. No entanto, para fins de apresentação, faremos uma interface gráfica bem simples, apenas para fins de demonstração da usabilidade do algoritmo.\n",
    "\n",
    "O workflow foi dividido em diversos passo, a saber:\n",
    "\n",
    "__- Passo 0: importação de bibliotecas__\n",
    "\t- Nesta etapa, importamos as bibliotecas necessárias para a implementação do algoritmo completo;\n",
    "\n",
    "__- Passo 1: leitura de dados__\n",
    "\t- Nesta etapa, importamos para o workflow as duas bases necessárias para a construção do modelo: a base de perguntas (que contém as perguntas e os respectivos intents classificados); e a base de produtos (que contém os produtos cadastrados).\n",
    "\n",
    "__- Passo 2: pré-processamento__\n",
    "\t- Nesta etapa, fazemos todo o pré-processamento de texto para a construção do modelo. É aqui que aplicamos as principais ferramentas de NLP (Processamento de Linguagem Natural, na sigla em inglês) para transformar o texto das perguntas em vetores numéricos que serão o input do modelo.\n",
    "\n",
    "__- Passo 3: modelagem preditiva__\n",
    "\t- Nesta etapa, construímos e treinamos o modelo de machine learning capaz de prever o intent de uma determinada frase. Também avaliamos a performance do modelo na base de validação.\n",
    "\n",
    "__- Passo 4: formulação das respostas__\n",
    "\t- Nesta etapa, construímos a resposta do bot para à pergunta feita. Para isso, usamos o intent predito pelo modelo para fazer uma query à base de produto, que contêm informações de cadastro do produto. A resposta do bot é então construída, utilizando as informações da base de produtos de maneira flexível.\n",
    "\n",
    "__- Passo 5: analytics__\n",
    "\t- Nesta etapa, tomamos a base de teste e avaliamos a performance do modelo, produzindo gráficos para auxiliar a interpretação dos resultados. Esta etapa simula como seria o modelo em produção, e que tipo de informações relevantes o usuário pode receber após o modelo estar em funcionamento.\n",
    "\n",
    "__- Passo 6: interface gráfica__\n",
    "\t- Nesta etapa, construímos a interface gráfica e a integramos com o modelo, de modo a simular o processo de perguntas e respostas na plataforma do marketplace.\n",
    "\n",
    "\n",
    "Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 0: importação de bibliotecas\n",
    "\n",
    "Usaremos as seguintes bibliotecas para as respectivas finalidades:\n",
    "\n",
    "- <a href=https://numpy.org/>Numpy</a>: para vetorização de dados;\n",
    "- <a href=https://pandas.pydata.org/>Pandas</a>: para manipulação de base dados;\n",
    "- <a href=https://www.nltk.org/>NLTK</a>: para ferramentas de NLP;\n",
    "- <a href=https://scikit-learn.org/stable/>Scikit-learn</a>: para modelagem estatística e machine learning;\n",
    "- <a href=https://www.tensorflow.org/>TensorFlow</a>: framework de redes neurais e deep learning;\n",
    "- <a href=https://keras.io/>Keras</a>: API de alto nível para o TensorFlow;\n",
    "- <a href=https://matplotlib.org/>Matplotlib</a>: para plots e visualizações;\n",
    "- <a href=https://seaborn.pydata.org/>Seaborn</a>: para plotagem estatística;\n",
    "- <a href=https://docs.python.org/3/library/tkinter.html>Tkinter</a>: para a construção da interface gráfica;\n",
    "- <a href=https://docs.python.org/3/library/random.html>random</a>: para números aleatórios;\n",
    "- <a href=https://docs.python.org/3/library/re.html>re</a>: para processamento de regex;\n",
    "- <a href=https://docs.python.org/3/library/ast.html>ast</a>: pra trasnformar string em dicionário;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando de principais bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.432920Z",
     "start_time": "2020-05-03T20:42:24.097476Z"
    }
   },
   "outputs": [],
   "source": [
    "#processamento de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#regex\n",
    "import re\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('rslp')\n",
    "\n",
    "#dataviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#random, para reproducibilidade\n",
    "import random\n",
    "\n",
    "#pra tirar acentos\n",
    "import unidecode\n",
    "\n",
    "#pra transformar string em dict\n",
    "import ast\n",
    "\n",
    "#para plotagem\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T14:12:59.701829Z",
     "start_time": "2020-05-03T14:12:59.696133Z"
    }
   },
   "source": [
    "Demais módulos específicos de outras bibliotecas serão importados conformea necessidade ao decorrer do processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "_______________\n",
    "_______________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 1: leitura de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo a base de perguntas\n",
    "\n",
    "A documentação da base está no repositório, no arquivo (...). Leia a documentação para informações detalhadas sobre a construção e conteúdo da base.\n",
    "\n",
    "A base de perguntas tem duas colunas e 1200 linhas, onde cada linha é relativa a uma pergunta, e as colunas são:\n",
    "\n",
    "- \"intent\" : contém um entre os 12 intents possíveis. Essa é a coluna de target do modelo;\n",
    "\n",
    "- \"pergunta\" : contém uma pergunta cuja intenção é dada pelo respectivo intent. Essa é a coluna de features do modelo (que deverá passar por um pré-processamento através de técnicas de NLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.517843Z",
     "start_time": "2020-05-03T20:42:25.435407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bases balanceada e desbalanceadas separadas com sucesso!\n",
      "\n",
      "Cinco primeiras linhas da base de treino:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>pergunta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Voltagem</td>\n",
       "      <td>É 110 volt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Garantia</td>\n",
       "      <td>amigo vou precisar de garantia pode me emitir ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bateria</td>\n",
       "      <td>Quantos mah tem essa bateria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dimensão</td>\n",
       "      <td>quantos cms tem?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acessórios</td>\n",
       "      <td>Ele vem com mause e teclado ? E estabilizador?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                           pergunta\n",
       "0    Voltagem                                         É 110 volt\n",
       "1    Garantia  amigo vou precisar de garantia pode me emitir ...\n",
       "2     Bateria                       Quantos mah tem essa bateria\n",
       "3    Dimensão                                   quantos cms tem?\n",
       "4  Acessórios     Ele vem com mause e teclado ? E estabilizador?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#numero de perguntas pra cada intent\n",
    "n = 100\n",
    "\n",
    "df_perguntas = pd.read_csv(\"base_treino_\" + str(n) + \".csv\")\n",
    "\n",
    "#é bom dar uma misturada...\n",
    "df_perguntas = df_perguntas.sample(frac=1, random_state = 42).reset_index(drop=True)\n",
    " \n",
    "#essa é a base desbalanceada\n",
    "df_desbalanc = df_perguntas[~df_perguntas[\"intent\"].isin(df_perguntas[\"intent\"].value_counts()[df_perguntas[\"intent\"].value_counts() == n].index.tolist())]\n",
    "\n",
    "#essa é a base balanceada (vou manter o mesmo nome)\n",
    "df_perguntas = df_perguntas[df_perguntas[\"intent\"].isin(df_perguntas[\"intent\"].value_counts()[df_perguntas[\"intent\"].value_counts() == n].index.tolist())]\n",
    "    \n",
    "if (~df_perguntas[\"intent\"].value_counts().values == n).sum() == 0:\n",
    "    print(\"Bases balanceada e desbalanceadas separadas com sucesso!\")\n",
    "    print(\"\\nCinco primeiras linhas da base de treino:\")\n",
    "    display(df_perguntas.head())\n",
    "else:\n",
    "    print(\"Erro... Olha o código!\")\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.626554Z",
     "start_time": "2020-05-03T20:42:25.520675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1200 entries, 0 to 1199\n",
      "Data columns (total 2 columns):\n",
      "intent      1200 non-null object\n",
      "pergunta    1200 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#informações rápidas sobre a composição da base\n",
    "\n",
    "df_perguntas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.703222Z",
     "start_time": "2020-05-03T20:42:25.630639Z"
    }
   },
   "outputs": [],
   "source": [
    "# # A seguir, eu pego algumas perguntas específicas de algumas classes, e adiciono aleatoriamente\n",
    "# # duas vezes às perguntas das classes correspondentes. \n",
    "# # Faço isso para aumentar o meu vocabulário com palavras bem importantes mas que provavelmente\n",
    "# # não estão na base de treino!\n",
    "\n",
    "# incremento = pd.read_excel(\"Dicionário.xlsx\")\n",
    "\n",
    "# for col in incremento.columns:\n",
    "    \n",
    "#     #cria uma lista com as palavras de cada intent pra incrementar\n",
    "#     lista_dic = incremento[col].dropna().unique().tolist()\n",
    "    \n",
    "#     for item in lista_dic:\n",
    "        \n",
    "#         for repeat in range(10):\n",
    "            \n",
    "#             n = random.randint(0, 99)\n",
    "            \n",
    "#             aux_perg = df_perguntas[df_perguntas[\"intent\"] == col].iloc[n][\"pergunta\"]\n",
    "            \n",
    "#             df_perguntas.loc[df_perguntas[\"pergunta\"] == aux_perg, \"pergunta\"] = aux_perg + \" \" + str(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.796156Z",
     "start_time": "2020-05-03T20:42:25.705322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temos 1200 perguntas na base.\n",
      "As perguntas estão distribuídas em diferentes intents.\n",
      "\n",
      "Temos 12 intents na base, com as respectivas quantidades de perguntas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Acessórios            100\n",
       "Voltagem              100\n",
       "Nota Fiscal           100\n",
       "Cor                   100\n",
       "Capacidade            100\n",
       "Garantia              100\n",
       "Estado                100\n",
       "Entrega               100\n",
       "Disponibilidade       100\n",
       "Bateria               100\n",
       "Meios de pagamento    100\n",
       "Dimensão              100\n",
       "Name: intent, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pequena análise exploratório do conteúdo da base\n",
    "\n",
    "perguntas = df_perguntas.iloc[:,1]\n",
    "print(\"\\nTemos\", len(perguntas), \"perguntas na base.\\nAs perguntas estão distribuídas em diferentes intents.\\n\")\n",
    "\n",
    "intents = df_perguntas.iloc[:,0]\n",
    "print(\"Temos\", len(intents.unique()), \"intents na base, com as respectivas quantidades de perguntas:\")\n",
    "display(intents.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo a base de produtos\n",
    "\n",
    "A documentação da base está no repositório, no arquivo (...). Leia a documentação para informações detalhadas sobre a construção e conteúdo da base.\n",
    "\n",
    "A base de produtos tem 13 colunas (uma para o nome do produto e 12 para os intents) e 10 linhas, onde cada linha se refere a um produto, e cada coluna contém um dicionário com as informações relativas àquele intente do respectivo produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.907561Z",
     "start_time": "2020-05-03T20:42:25.798476Z"
    }
   },
   "outputs": [],
   "source": [
    "base_de_produtos = pd.read_csv(\"base_produto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:25.993644Z",
     "start_time": "2020-05-03T20:42:25.910214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 13 columns):\n",
      "Produto               10 non-null object\n",
      "Acessórios            10 non-null object\n",
      "Cor                   10 non-null object\n",
      "Capacidade            10 non-null object\n",
      "Bateria               10 non-null object\n",
      "Dimensão              10 non-null object\n",
      "Disponibilidade       10 non-null object\n",
      "Entrega               10 non-null object\n",
      "Estado                10 non-null object\n",
      "Garantia              10 non-null object\n",
      "Meios de pagamento    10 non-null object\n",
      "Nota Fiscal           10 non-null object\n",
      "Voltagem              10 non-null object\n",
      "dtypes: object(13)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#informações rápidas sobre a composição da base\n",
    "\n",
    "base_de_produtos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.083232Z",
     "start_time": "2020-05-03T20:42:25.998922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo de cadastro do primeiro produto na base:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Produto               {\"produto\": \"Controle joystick Sony Dualshock ...\n",
       "Acessórios                                               {\"controle\":1}\n",
       "Cor                                                         {\"azul\": 1}\n",
       "Capacidade                                                           {}\n",
       "Bateria                                           {\"duracao\":\"8 horas\"}\n",
       "Dimensão              {\"comprimento\":\"5 cm\",\"largura\":\"10 cm\",\"altur...\n",
       "Disponibilidade                                           {\"estoque\":1}\n",
       "Entrega               {\"texto\":\"Entregamos para todo o Brasil, favor...\n",
       "Estado                {\"texto\":\"Nossos produtos são novos, originais...\n",
       "Garantia              {\"garantia_fornecedor\":\"90 dias\",\"garantia_oli...\n",
       "Meios de pagamento    {\"cartao_credito\":\"sim\",\"cartao_debito\":\"nao\",...\n",
       "Nota Fiscal                                              {\"nota\":\"sim\"}\n",
       "Voltagem                                                     {\"120V\":1}\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Exemplo de cadastro do primeiro produto na base:\\n\")\n",
    "base_de_produtos.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.171556Z",
     "start_time": "2020-05-03T20:42:26.086994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produtos cadastrados na base:\n",
      "\n",
      "Controle joystick Sony Dualshock 4 500 million limited edition;\n",
      "Ventilador de mesa Arno VF;\n",
      "Samsung Galaxy J2;\n",
      "Piscina estrutural Botafogo PIS0628;\n",
      "Pendrive SanDisk Cruzer Blade;\n",
      "Pipoqueira elétrica Lenoxx PPC 953;\n",
      "Churrasqueira móvel Mec G CHUIN02;\n",
      "Relógio Digital Unissex Champion Ch40080t;\n",
      "Forno Elétrico Inox Premium Lenoxx- Pfo 303;\n",
      "Controle Remoto Tv Cce Mod Rc-517\n"
     ]
    }
   ],
   "source": [
    "#lista dos produtos construida a partir da base de produtos\n",
    "lista_de_produtos = [list(ast.literal_eval(item).values())[0] for item in base_de_produtos[\"Produto\"].tolist()]\n",
    "\n",
    "print(\"Produtos cadastrados na base:\\n\")\n",
    "print(*lista_de_produtos, sep=\";\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "_______________\n",
    "_______________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2: pré-processamento\n",
    "\n",
    "Nesta etapa, vamos aplicar as técnicas de NLP para a criação do corpus e do modelo de bag-of-words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do corpus a partir das perguntas da base de treino\n",
    "\n",
    "A etapa de pré-processamento dos dados é de extrema importância em todo projeto de ciência de dados. Muitas vezes os dados coletados não podem ser utilizados na construção de um modelo antes que este sejam processadas. \n",
    "\n",
    "No nosso caso, nossos dados de treino são perguntas (portanto, do tipo de dados string). Acontece que os modelos de machine learning não aceitam strings como input, apenas dados numéricos! Para isso, teremos de transformar as strings de perguntas em alguma forma de representação numérica. Para fazer isso, usaremos as técnicas de NLP!\n",
    "\n",
    "A primeira etapa é a construção do corpus, que nada mais é que uma lista com todas as perguntas da base de treino após sua limpeza. A limpeza consiste nos seguintes passos:\n",
    "\n",
    "- Retirada de caracteres que não agregam significado, como pontuações (\"!\", \"(\", \".\", etc) e números (embora mantemos os números 0, 1 e 2 pois estes são úteis para o intent de \"Voltagem\");\n",
    "\n",
    "- Conversão de todas as letras em minúsculas, para que não haja distinção entre palavras capitalizadas ou não;\n",
    "\n",
    "- Aplicação de stemming, que consiste na limpeza de sufixos, prefixos e terminações das palavras, de modo que reste apenas sua raiz sintática. Testamos diversos stemmers disponíveis para o português, e o mais adequado foi o <a href=https://snowballstem.org/>Snowball (Porter2)</a>.\n",
    "\n",
    "- Retirada de stopwords da língua portuguesa, que são palavras que não agregam significado para a determinação dos intents (em especial entram aqui artigos e preposições).\n",
    "\n",
    "É importante ressaltar que a escolha das etapas de pré-processamento não é algo óbvio, dado que há muitas escolhas possíveis acerca do que se fazer para pré-processar os dados. As etapas que descrevemos acima foram definidas apenas depois de muitos testes iterativos, onde aplicamos diferentes combinações de técnicas de pré-processamento, conforme é descrito no Notebook (...). A combinação de processos descrita acima foi a que gerou os melhores resultados, e por isso foi a que escolhemos para o modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.436872Z",
     "start_time": "2020-05-03T20:42:26.174472Z"
    }
   },
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stpwrds = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "#essa é a função de pre-processamento\n",
    "def pre_proc(pergunta, stpwrds=stpwrds):\n",
    "    \n",
    "    #vamos jogar fora tudo que não são letras minusculas e maiusculas (incluido acentuações)\n",
    "    #vou manter também apenas os numeros 0,1,2, pra poder captar 110 e 220\n",
    "    pergunta = re.sub(\"[^a-zA-ZáàâãéèêíïóôõöúçñÁÀÂÃÉÈÍÏÓÔÕÖÚÇÑ0-2]\", \" \", pergunta)\n",
    "\n",
    "    #deixa tudo minuscula\n",
    "    pergunta = pergunta.lower()\n",
    "\n",
    "    #tonkeniza\n",
    "    pergunta = pergunta.split()\n",
    "\n",
    "    #stemmer SB\n",
    "    stemmer = nltk.stem.SnowballStemmer('portuguese')\n",
    "        \n",
    "    #tira stopwprds. tora acentps e aplica o stemmer\n",
    "    pergunta = [stemmer.stem(unidecode.unidecode(word)) for word in pergunta if word not in set(stpwrds)]\n",
    "\n",
    "    #refaz a string\n",
    "    pergunta = \" \".join(pergunta)\n",
    "\n",
    "    return pergunta\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for item in perguntas:\n",
    "\n",
    "    pergunta = pre_proc(item, stpwrds)\n",
    "\n",
    "    #adiciona ao corpus\n",
    "    corpus.append(pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.441323Z",
     "start_time": "2020-05-03T20:42:26.438738Z"
    }
   },
   "outputs": [],
   "source": [
    "# #aqui eu mostro a pergunta original e a versão pré-processada. Deixei comentado porque isso é muito grande. \n",
    "# #pra ver, é só descomentar e rodar\n",
    "\n",
    "# print(\"\\nComparação entre a pergunta original e a versão pré-processada da pergunta no corpus:\\n\")\n",
    "\n",
    "# for i in range(len(perguntas)):\n",
    "#     print(perguntas[i], \"|\", corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a construção do Corpus, a próxima etapa é a construção do modelo de bag-of-words, que tem como objetivo transformar as strings de perguntas do corpus (features textuais) em vetores (features numéricas). Para isso, precisamos criar o vocabulário do corpus, e logo após fazer o <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html>one-hot encoding</a> de cada pergunta. Vamos fazer estas etapas separadamente a seguir, e discutir cada uma em maiores detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulário\n",
    "\n",
    "O vocabulário do corpus nada mais é do que uma listagem das palavras individuais que aparecem no corpus. Para encontrar o vocabulário, basta contarmos a aparição de cada palavra isolada no corpus. Ao fim, teremos N palavras únicas que compõem nosso vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.791433Z",
     "start_time": "2020-05-03T20:42:26.443417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O vocabulário é formado por N = 808 palavras!\n",
      "\n",
      "Temos a seguir as 10 mais comuns, com as respectivas contagens:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palavra</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>quant</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>boa</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vem</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>garant</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bat</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>produt</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>cor</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>tard</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>not</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dia</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    palavra  count\n",
       "9     quant    151\n",
       "61      boa    111\n",
       "13      vem    109\n",
       "5    garant     98\n",
       "11      bat     80\n",
       "65   produt     69\n",
       "78      cor     65\n",
       "62     tard     61\n",
       "105     not     60\n",
       "20      dia     58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A quantidade de palavras com apenas uma aparição no corpus (palavras raras)\n",
      "é de 412, o que equivale a 50.99% da base.\n"
     ]
    }
   ],
   "source": [
    "#só pra ter uma ideia do vocabulário, vamos fazer uma lista de listas com o formato:\n",
    "#vocabulario[i] = [palavra, numero_de_aparicoes_no_corpus]\n",
    "\n",
    "vocabulario = []\n",
    "for pergunta in corpus:\n",
    "    for palavra in pergunta.split():\n",
    "        #não queremos palavras de uma única letra (pode acontecer devido ao stemming...)\n",
    "        if len(palavra) > 1:\n",
    "            if palavra not in [x[0] for x in vocabulario]:\n",
    "                vocabulario.append([palavra, 1])\n",
    "            else:\n",
    "                vocabulario[[x[0] for x in vocabulario].index(palavra)][1] += 1\n",
    "            \n",
    "print(\"\\nO vocabulário é formado por N =\", len(vocabulario), \"palavras!\")\n",
    "\n",
    "#a partir do vocabulário, crio um dataframe com a contagem\n",
    "vocab_count = pd.DataFrame({\"palavra\": [],\n",
    "                           \"count\": []})\n",
    "\n",
    "vocab_count[\"palavra\"] = pd.Series(vocabulario).apply(lambda x: x[0])\n",
    "vocab_count[\"count\"] = pd.Series(vocabulario).apply(lambda x: x[1])\n",
    "vocab_count = vocab_count.sort_values(\"count\", ascending=False)\n",
    "\n",
    "print(\"\\nTemos a seguir as 10 mais comuns, com as respectivas contagens:\")\n",
    "display(vocab_count.head(10))\n",
    "\n",
    "raras = vocab_count[vocab_count[\"count\"] == 1]\n",
    "prop_raras = raras.shape[0]/vocab_count.shape[0]\n",
    "print(\"\\nA quantidade de palavras com apenas uma aparição no corpus (palavras raras)\\né de \" + str(raras.shape[0]) +\n",
    "     \", o que equivale a\", str(round(100*(prop_raras), 2)) + \"% da base.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words\n",
    "\n",
    "Após estudarmos o vocabulário, vamos efetivamente montar o modelo de bag-of-words. Este modelo funciona da seguinte forma:\n",
    "\n",
    "- Pegue uma frase do corpus;\n",
    "- Crie um vetor N-dimensional de inteiros (onde N é o número de palavras do vocabulário);\n",
    "- Cada componente do vetor corresponde a uma palavra do vocabulário, segundo a ordem que as palavras aparecem no vocabulário.\n",
    "- Preencha esse vetor com zeros (todas suas componentes serão 0);\n",
    "- Para cada palavra da frase, mude a componente correspondente do vetor para 1;\n",
    "- Faça isso para todas as frases do corpus;\n",
    "\n",
    "Ao fim do processo acima para todas as frases do corpus (supomos que sejam M frases), nós empilhamos os respectivos vetores, de modo que teremos uma matriz de M linhas e N colunas. E essa matriz é o modelo final de bag-of-words, que por ser uma matriz numérica, pode ser facilmente usada como input pros modelos de machine learning!\n",
    "\n",
    "Pra exemplificar o procedimento, vamos a um exemplo: suponha que nossa base de treino contenha as seguintes 3 frases (M = 3):\n",
    "\n",
    "[\"Qual é a cor do produto?\",<br>\n",
    "\"O produto vem com a Nota Fiscal?\",<br>\n",
    "\"Qual o prazo de entrega pra SP?\"]\n",
    "\n",
    "Após o pre-processamento inicial das frases, o corpus final fica sendo:\n",
    "\n",
    "[\"cor produt\",<br>\n",
    "\"produt vem not fiscal\",<br>\n",
    "\"praz entreg pra sp\"]\n",
    "\n",
    "Olhando pro corpus, é fácil ver que nosso vocabulário é:\n",
    "\n",
    "[\"cor\", \"produt\", \"vem\", \"not\", \"fiscal\", \"praz\", \"entrega\", \"pra\", \"sp\"].\n",
    "\n",
    "É útil deixarmos o vocabulário em ordem alfabética:\n",
    "\n",
    "[\"cor\", \"entrega\", \"fiscal\", \"not\", \"pra\", \"praz\", \"produt\", \"sp\", \"vem\"].\n",
    "\n",
    "Temos N = 9 palavras no vocabulário. O one-hot encoding de cada uma das frases do corpus irá, então, produzir um vetor 9-dimensional de 1 e 0, com 1 nas posições respectivas às palavras no vocabulário. Vamos entender:\n",
    "\n",
    "Para a frase \"cor produt\", teremos um vetor com o numero 1 nas posições 0 (posição da palavra \"cor\") e 6 (posição da palavra \"produt\" do vocabulário, de forma que temos o vetor:\n",
    "\n",
    "\"cor produt\" --> [1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "\n",
    "Analogamente, para as outras duas frases, teremos os vetores:\n",
    "\n",
    "\"produt vem not fiscal\" --> [0, 0, 1, 1, 0, 0, 1, 0, 1]\n",
    "\n",
    "\"praz entreg pra sp\" --> [0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "Finalmente, o modelo de bag-of-words (BoW) final é a matriz de dimensão 3 x 9 (M = 3 frases no corpus, N = 9 palavras no vocabulário), obtida ao empilhar os vetores:\n",
    "  \n",
    "$ BoW = \\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 1 & 0 & 0 & 1 & 0 & 1 \\\\\n",
    "0 & 1 & 0 & 0 & 1 & 1 & 0 & 1 & 0\n",
    "\\end{pmatrix} $\n",
    "\n",
    "Com esse exemplo, esperamos que o procedimento geral tenha ficado bem claro! :)\n",
    "\n",
    "Naturalmente, tanto nosso corpus quanto nosso vocabulário serão muito maiores que os desse exemplo simples. Mas, o procedimento é exatamente o mesmo, e no final, teremos exatamente o mesmo output do modelo de bag-of-words: uma matriz M x N de 0 e 1, prontinha pra ser input dos modelos de machine learning!\n",
    "\n",
    "Para fazer o bag of words propriamente, vamos usar o <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html>CountVectorizer</a> do sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.824900Z",
     "start_time": "2020-05-03T20:42:26.794263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As dimensões da matriz de features estão corretas!\n",
      "\n",
      "Bag of words feito com sucesso!\n",
      "\n",
      "O modelo BoW é uma matriz com as dimensões (1200, 808)\n",
      "(pois, como vimos, temos M = 1200 frases no corpus e N = 808 palavras no vocabulário)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#o max_feacutres imita o tamanho do vocabulario.. Não sei o quanto é interessante\n",
    "# cv = CountVect}orizer(max_features = 1500)\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#features\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "#target\n",
    "# y = intents_num\n",
    "y = intents.values\n",
    "\n",
    "#validação\n",
    "if X.shape[1] == vocab_count.shape[0] and X.shape[0] == len(perguntas):\n",
    "    print(\"As dimensões da matriz de features estão corretas!\")\n",
    "    print(\"\\nBag of words feito com sucesso!\")\n",
    "    print(\"\\nO modelo BoW é uma matriz com as dimensões\", X.shape)\n",
    "    print(\"(pois, como vimos, temos M =\", X.shape[0], \"frases no corpus e N =\", X.shape[1] , \"palavras no vocabulário)\")\n",
    "else:\n",
    "    print(\"As dimensões não batem! Reveja o código!\")\n",
    "    for item in [x[0] for x in vocabulario]:\n",
    "        if item not in list(cv.vocabulary_.keys()):\n",
    "            print(item)\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "_______________\n",
    "_______________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 3: modelagem preditiva\n",
    "\n",
    "Agora vem a etapa de construção do modelo!\n",
    "\n",
    "Relembrando: o que queremos é um modelo que tenha como input uma frase (já pré-processada e vetorizada), e como output um dos intents.\n",
    "\n",
    "Com isso, fica claro que precisamos de um __modelo de classificação multiclasse__, pois nosso objetivo é justamente classificar a pergunta de input entre uma das 12 classes (intents) possíveis!\n",
    "\n",
    "Existem muitos modelos de classificação, e nós testamos muitos deles, como pode-se ver explicitamente no notebook (...). Os modelos que testamos (com combinações diferentes de hiperparâmetros) foram:\n",
    "\n",
    "- Naive Bayes;\n",
    "- Support Vector Machine;\n",
    "- Random Forrest;\n",
    "- Redes neurais;\n",
    "- Regressão Logística Multinomial.\n",
    "\n",
    "Dentre os testes que fizemos, todos os modelos tiveram boa performance. No entanto, devido à sua simplicidade e flexibilidade, decidimos por utilizar como modelo final a regressão logística multinomial, como apresentaremos a seguir.\n",
    "\n",
    "Naturalmente, poderíamos testar ainda outras combinações de hiperparâmetros, bem como outros modelos mais complexos (XGBoost, outras arquiteturas de redes neurais, etc.). No entanto, devido às limitações de tempo e às muitas outras atividades envolvidas neste hackathon, decidimos por não dedicar tanto tempo neste processo iterativo de escolha de modelo.<br>\n",
    "Ademais, como veremos mais à frente, o modelo simples que escolhemos já é altamente preciso, de modo que, dado o tempo limitado que temos, ele já nos supre muito bem.\n",
    "\n",
    "Os passos que seguiremos, detalhados a seguir, são:\n",
    "\n",
    "- Train-test split;\n",
    "- Modelagem;\n",
    "- Validação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "Aqui, separamos nossa base de treino entre os dados que efetivamente serão usados para o treinamento do modelo, e dados que serão usados para a validação, na proporção de 80% pra treino e 20% pra validação. Os dados que compõem cada um dos conjuntos de teste e validação são selecionados aleatoriamente, mas estratificados de modo a garantir o balanceamento das classes, como já explicamos ser importante.\n",
    "\n",
    "Os dados de validação _não_ são usados para o treinamento, e, assim sendo, podemos utilizá-los para testar a performance do modelo em dados não vistos em treinamento. A performance encontrada dará uma ideia do grau de viés e variância do modelo, isto é, entenderemos se o modelo sofre de overfitting ou underfitting, ao mensurarmos o quanto que suas previsões são generalizadas para dados não vistos em treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:26.936165Z",
     "start_time": "2020-05-03T20:42:26.826875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check de balanço do train-test split:\n",
      "\n",
      "Número de exemplos de cada intent para treino:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Acessórios            80\n",
       "Voltagem              80\n",
       "Nota Fiscal           80\n",
       "Cor                   80\n",
       "Capacidade            80\n",
       "Garantia              80\n",
       "Estado                80\n",
       "Entrega               80\n",
       "Disponibilidade       80\n",
       "Bateria               80\n",
       "Meios de pagamento    80\n",
       "Dimensão              80\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de exemplos de cada intent para validação:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cor                   20\n",
       "Acessórios            20\n",
       "Capacidade            20\n",
       "Nota Fiscal           20\n",
       "Voltagem              20\n",
       "Garantia              20\n",
       "Estado                20\n",
       "Entrega               20\n",
       "Disponibilidade       20\n",
       "Dimensão              20\n",
       "Bateria               20\n",
       "Meios de pagamento    20\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)\n",
    "\n",
    "print(\"Check de balanço do train-test split:\")\n",
    "\n",
    "print(\"\\nNúmero de exemplos de cada intent para treino:\")\n",
    "display(pd.Series(y_train).value_counts())\n",
    "\n",
    "print(\"\\nNúmero de exemplos de cada intent para validação:\")\n",
    "display(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção do modelo - Multinomial Logistic Regression\n",
    "\n",
    "Conforme discutimos acima, utilizaremos como modelo de classificação uma regressão logística multinomial (ao qual nos referiremos como multi-logit).\n",
    "\n",
    "O multi-logit é um modelo cujo objetivo é calcular, com base nas features (no caso, a pergunta vetorizada depois do pré-processamento) qual é a __probabilidade da pergunta ser classificada como cada um dos intents__. Ao \"ler\" a pergunta, o modelo atribui uma probabilidade a cada uma das classes, e aí a classe escolhida é simplesmente aquela com maior probabilidade! Simples, não é mesmo?\n",
    "\n",
    "Temos apenas uma pequena complicação, que trataremos mais adiante, que é o caso em que há mais de um intent na mesma pergunta: um potencial cliente pode muito bem perguntar, na mesma pergunta, quais as cores disponíveis do produto, e quais as formas de pagamento. Nosso modelo deve também tentar responder a estas perguntas com mais de um intent. Mas este problema nós abordaremos um pouco mais adiante. \n",
    "\n",
    "Por enquanto, basta entendermos o funcionamento da regressão logística: que no final atribui uma probabilidade da pergunta pertencer a cada uma das classes, isto é, o multi-logit é uma função que retornará uma probabilidade de cada classe (intent) $C$, que chamaremos de $P_C(X)$, onde $X$ é o vetor de features correspondente à pergunta (aquele vetor cheio de zeros e alguns 1's).\n",
    "\n",
    "Naturalmente, queremos que a função $P_C(X)$, por ser uma probabilidade, esteja limitada entre 0 e 1. Um exemplo de tal função é a função sigmoidal ou __função logística__:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"sigm.png\" height=\"400\" width=\"400\">\n",
    "    <figcaption>\n",
    "        Função Logística. Fonte:\n",
    "        <a href=\"https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png\">Towards Data Science</a>\n",
    "    </figcaption>\n",
    "</figure> \n",
    "\n",
    "E é por isso que o modelo éde \"regressão logística\", poid o mofrlo é construído com base na função logística ilustrada acima (embora a ilustração acima seja mais adequada para um problema de classificação binária. No nosso caso, que temos muitas classes, temos o multi-logit, cuja representação é mais difícil, e, portanto, não mostraremos aqui).\n",
    "\n",
    "Agora, vamos construir o modelo a partir da <a href=https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html>classe</a> do sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:27.569200Z",
     "start_time": "2020-05-03T20:42:26.937905Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: multi-logit\n",
      "\n",
      "Parâmetros: LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Modelo treinado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "#Construção do modelo\n",
    "\n",
    "#importa o modelo do sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = \"multi-logit\"\n",
    "#instancia o modelo com definição de hiperparâmetros\n",
    "logit = LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\", C=10, penalty='l2', random_state = 42,\n",
    "                           class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "                           n_jobs=None, tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "print(\"Modelo:\", modelo)\n",
    "print(\"\\nParâmetros:\", logit)\n",
    "\n",
    "#fita o modelo\n",
    "fit = logit.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nModelo treinado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação\n",
    "\n",
    "\n",
    "Com o modelo treinado, podemos usá-lo para fazer previsões!\n",
    "\n",
    "Antes de prosseguirmos, vamos quantificar qual é a peformance do modelo quando aplicado aos dados da base de validação.\n",
    "\n",
    "Lembrando que separamos a base de validação no processo de train-test split, onde criamos as features de validação \"X_test\" e os targets de validação (targets reais) \"y_test\", que contêm os intents reais, conforme a base de perguntas. \n",
    "\n",
    "Utilizamos o modelo treinado pra criar os targets preditos pelo modelo, \"y_pred\", que são os intents preditos pelo algoritmo. \n",
    "\n",
    "Uma vez em posse de \"y_test\" e \"y_pred\", podemos simplesmente comparar os dois targets, e então saber qual é a performance do modelo, ao mensurarmos os acertos (quando \"y_pred\" = \"y_test\") e erros (quando \"y_pred\" = \"y_test\").\n",
    "\n",
    "Para mensurarmos de forma sistemática, utilizaremos o <a href = https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html>classification report</a> do sklearn, que calula as <a href=https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9>métricas de classificação</a> habituais: precision, recall e o f1-score, para cada uma das classes.\n",
    "\n",
    "Como podemos ver, a performance do modelo é muito boa, com um f1-score médio de 93%! Isso realmente é muito notável, e se deve em particular devido aos grandes esforços aplicados ao pré-processamento dos dados, bem como à escolha adequada do modelo e seus hiperparâmetros.\n",
    "\n",
    "Embora tal precisão seja muito elevada, tanto à ponto de chamar atenção para possíveis erros de superestimação das métricas de performance, chamamos a atenção para os dados que temos e o tipo de problema que estamos querendo resolver: naturalmente, nossos dados são concentrados, dado que não existe uma variabilidade imensa de perguntas para cada um dos intents. Assim sendo, a cuidadosa coleta e pre-processamento dos dados, garantem esta performance altíssima.<br>\n",
    "Além disso, é natural que esperemos um modelo de alta performance, pois é fundamental que as respostas sejam precisas!\n",
    "\n",
    "Por fim, no entanto, ressaltamos que a performance com os dados de validação geralmente é maior do que a performance real do modelo em produção. Isto acontece porque, com o train-test split, tomamos dados de treino e validação de uma distribuição bem similar, o que favorece uma boa performance.\n",
    "\n",
    "Mais adiante, testaremos o modelo em uma base de teste realmente independente, desbalanceada, e cuja coleta foi menos cuidadosa. Esta base, sim, servirá como real teste para os casos que o modelo pode encontrar quando for posto em produção, de modo que provavelmente terá métricas de performance um pouco menores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:27.635161Z",
     "start_time": "2020-05-03T20:42:27.588349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação:\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        Acessórios       0.95      1.00      0.98        20\n",
      "           Bateria       0.95      0.90      0.92        20\n",
      "        Capacidade       0.95      0.90      0.92        20\n",
      "               Cor       0.90      0.95      0.93        20\n",
      "          Dimensão       0.95      1.00      0.98        20\n",
      "   Disponibilidade       0.75      0.90      0.82        20\n",
      "           Entrega       0.94      0.80      0.86        20\n",
      "            Estado       0.86      0.90      0.88        20\n",
      "          Garantia       1.00      1.00      1.00        20\n",
      "Meios de pagamento       1.00      0.95      0.97        20\n",
      "       Nota Fiscal       1.00      0.95      0.97        20\n",
      "          Voltagem       1.00      0.95      0.97        20\n",
      "\n",
      "         micro avg       0.93      0.93      0.93       240\n",
      "         macro avg       0.94      0.93      0.93       240\n",
      "      weighted avg       0.94      0.93      0.93       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "\n",
    "#validação\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#usa o modelo para calular predições\n",
    "y_pred = fit.predict(X_test)\n",
    "\n",
    "print(\"\\nAvaliação:\\n\")\n",
    "\n",
    "#mostra o classification report das predições\n",
    "print(classification_report(y_test, y_pred))\n",
    "#a matriz de confusão não é tão esclarecedora no nosso caso com 12 classes, por isso comentei\n",
    "# print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "_______________\n",
    "_______________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 4: formulação das respostas\n",
    "\n",
    "Após a determinação do intent de uma pergunta sobre determinado produto pela componente inteligente do modelo, temos de consultar na base de cadastro do produto quais são as informações cadastradas para o intent em questão, para então construir a resposta do robô, que deve conter estas informações cadastradas.\n",
    "\n",
    "A base de produtos é fundamental para que respostas correta sejam retornadas pelo robô, afinal, não é suficiente o robô dizer que entendeu sobre o que a pergunta se trata: ele deve retornar a resposta completa! \n",
    "\n",
    "Certamente a Olist tem uma base de cadastro para cada produto, que, conforme investigamos, são cadastrados no formato json. Como não tivemos acesso a este cadastro, nós mesmos construímos a base de produtos, que tivesse um formato facilmente adaptável a um json. \n",
    "\n",
    "Para isso, coletamos 10 produtos diferentes, conforme já mencionamos, e cadastramos em um dicionário seus atributos de acordo com cada um dos 12 intents que definimos anteriormente. Naturalmente, há intents que não estão definidos para alguns produtos, em cujo caso o campo respectivo foi cadastrado como vazio.\n",
    "\n",
    "Como exemplo da estrutura de dicionários, mostramos a seguir as cores disponíveis do produto \"Samsung Galaxy J2\":\n",
    "\n",
    "{\"azul\": 0 ,\"dourado\":1,\"lavanda\":26,\"preto\":104,\"púrpura\":0},\n",
    "\n",
    "O que segue o formato: {\"nome da cor\" : quantidade de produtos disponíveis naquela cor}.\n",
    "\n",
    "O formato é consistente em todos os registros de determinada coluna, mas varia entre as diferentes colunas (pois cada intent tem informações específicas e variável entre os intents).\n",
    "\n",
    "Então, nesta etapa, o que fazemos é construir as funções necessárias para o funcionamento completo do bot:\n",
    "\n",
    "- resposta_especificas(): é a função que monta a resposta com base nas informações relativas ao intent que foram cadastradas na base de produtos. Cada resposta segue uma estrutura fixa dentro de determinado intent, mas é absolutamente flexível para que os dados do produto específico sejam exibidos! Como input, a função tem:\n",
    "\t- O intent da pergunta, conforme classificado pelo modelo;\n",
    "\t- O dicionário correspondente ao intent e ao produto à que a pergunta se refere;\n",
    "\n",
    "- respostas_bot(): é a função que efetivamente retorna a resposta à pergunta. Como input, a função tem:\n",
    "\t- O produto ao qual a pergunta se refere;\n",
    "\t- A própria base de produtos;\n",
    "\t- O intent previsto pelo modelo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:27.734354Z",
     "start_time": "2020-05-03T20:42:27.657974Z"
    }
   },
   "outputs": [],
   "source": [
    "# essa resposta constrói a resposta final de acordo com cada intent.\n",
    "# os argumentos são: \n",
    "# o dicionario de intents dic_intent do respectivo produto; \n",
    "# o dicionario de respostas iniciais respostas_inicio; \n",
    "# o intent(que é output do modelo)\n",
    "def resposta_especificas(dic_intent, intent):\n",
    "    \n",
    "    #dicionario com a base das respostas\n",
    "    respostas_inicio = {'Acessórios': 'Olá! O(s) seguinte(s) item(s) vem junto com o produto: ', \n",
    "                         'Bateria': 'Olá! A bateria do produto tem as seguintes características: ', \n",
    "                         'Capacidade': 'Olá! O produto tem as seguintes especificações de capacidade: ', \n",
    "                         'Cor': 'Olá! Temos as seguintes cores disponíveis: ', \n",
    "                         'Dimensão': 'Olá! As dimensões do produto são: ', \n",
    "                         'Disponibilidade': 'Olá! ',\n",
    "                         'Entrega': 'Olá! ',\n",
    "                         'Estado': 'Olá! ', \n",
    "                         'Garantia': 'Olá! O produto tem as seguintes garantias: ', \n",
    "                         'Meios de pagamento': 'Olá! Os meios de pagamento que aceitamos são: ', \n",
    "                         'Nota Fiscal': 'Olá! ', \n",
    "                         'Voltagem': 'Olá! '}\n",
    "    \n",
    "    #no caso do produto não ter informação cadastrada pro respectivo intent\n",
    "    if dic_intent == {}:\n",
    "        resposta = \"Olá! Não tenho esta informação cadastrada. Te retornarei novamente mais tarde!\"\n",
    "    else:\n",
    "        #pros intents que tem textinho cadastrado, a resposta é o texto direto, e fim\n",
    "        if \"texto\" in list(dic_intent.keys()):\n",
    "            resposta = respostas_inicio[intent] + dic_intent[\"texto\"]\n",
    "        else:\n",
    "            resposta = respostas_inicio[intent]\n",
    "\n",
    "            if intent == 'Acessórios':\n",
    "\n",
    "                #pra ajustar o ponto final\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    #se tem apenas uma key no dict, eu coloco o ponto final\n",
    "                    #coloco tb o ponto final se for a ultima key do dict (usando a variavel count)\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + str(dic_intent[item]) + \" \" + item + \". \"\n",
    "                    #se tem mais de um acessório, eu os separo por ponto e virgula\n",
    "                    else:\n",
    "                        resposta = resposta + str(dic_intent[item]) + \" \" + item + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Bateria':\n",
    "\n",
    "                #listagem\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Capacidade':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "\n",
    "                        #pro caso de eu ter uma lista de opçoes disponiveis (como pra memoria ram)\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \".\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \";\\n\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Cor':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        #se nao tiver daquela cor disponível\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + \"- \" + item + \" (\" + str(dic_intent[item]) + \" unidade(s))\" + \". \"\n",
    "                    else:\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + \"- \" + item + \" (\" + str(dic_intent[item]) + \" unidade(s))\" + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Dimensão':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "\n",
    "                        #pro caso de eu ter uma lista de opçoes disponiveis (como pra memoria ram)\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \".\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \";\\n\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Disponibilidade':\n",
    "\n",
    "                #nessa coluna só vai ter o atributo \"estoque\", com a quantidade em estoque\n",
    "                if dic_intent[\"estoque\"] == 0:\n",
    "                    resposta = resposta + \"Infelizmente, o produto não está mais disponível.\"\n",
    "                else:\n",
    "                    resposta = resposta + \"O produto está disponível! Temos \" + str(dic_intent[\"estoque\"]) + \" unidades em estoque.\"\n",
    "\n",
    "            elif intent == 'Garantia':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + \"- \" + item.replace(\"_\", \" \") + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        resposta = resposta + \"- \" + item.replace(\"_\", \" \") + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Meios de pagamento':\n",
    "\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        #listo apenas as formas de pagamento disponíveis\n",
    "                        if dic_intent[item] == \"sim\":\n",
    "                            resposta = resposta + item.replace(\"_\", \" \") + \". \"\n",
    "                    else:\n",
    "                        if dic_intent[item] == \"sim\":\n",
    "                            resposta = resposta + item.replace(\"_\", \" \") + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Nota Fiscal':\n",
    "\n",
    "                #so tem esse atributo no dicionario de nota fiscal\n",
    "                if dic_intent[\"nota\"] == \"sim\":\n",
    "                    resposta = resposta + \"O produto será enviado juntamente da Nota Fiscal!\"\n",
    "                elif dic_intent[\"nota\"] == \"nao\":\n",
    "                    resposta = resposta + \"Não emitimos Nota Fiscal.\"\n",
    "\n",
    "            elif intent == 'Voltagem':\n",
    "\n",
    "                resposta = resposta + \"Temos \"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + str(dic_intent[item]) + \" unidades de \" + item + \".\"\n",
    "                    else:\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + str(dic_intent[item]) + \" unidades de \" + item + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:27.836067Z",
     "start_time": "2020-05-03T20:42:27.736217Z"
    }
   },
   "outputs": [],
   "source": [
    "#essa é a função que dá a resposta do bot.\n",
    "# seus argumentos são:\n",
    "# - a base de produtos \"base_de_produtos\" (que eu já tenho de ter lido)\n",
    "# - intent, que é o output do modelo\n",
    "# - produto, que é o produto ao qual a pergunta se refere. Isso entra a partir da GUI\n",
    "#dentro desta tem uma que é ainda mais importante, e que eu defini acima, a \"resposta_especificas()\"\n",
    "\n",
    "def respostas_bot(prod = base_de_produtos, intent = \"\", produto = \"\"):\n",
    "\n",
    "    #lista dos produtos construida a partir da base de produtos\n",
    "    lista_de_produtos = [list(ast.literal_eval(item).values())[0] for item in prod[\"Produto\"].tolist()]\n",
    "\n",
    "    #ve qual é o indice de linha do dataframe de produtos correspondentes ao produto a que se refere a pergunta\n",
    "    indice_linha = lista_de_produtos.index(produto)\n",
    "\n",
    "    #dicionario do respectivo produto e do respectivo intent\n",
    "    dic_intent = ast.literal_eval(prod.loc[indice_linha, intent])\n",
    "    \n",
    "    #completa a resposta\n",
    "    resposta_final = resposta_especificas(dic_intent, intent)\n",
    "                 \n",
    "    return resposta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as funções acima, nosso bot está completo: dada uma pergunta, o bot identifica a qual intent a pergunta pertence (componente inteligente), faz a consulta à base de perguntas e monta a pergunta (componente de consulta), e, por fim, retorna a pergunta ao usuário!\n",
    "\n",
    "As funções construídas acima serão todas integradas à interface, para que possamos simular o processo de perguntas e respostas. Faremos isso mais adiante, logo após a etapa de analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 6: Analytcs\n",
    "\n",
    "É nesta etapa que efetivamente vamos testar o modelo, utilizando a base de testes!\n",
    "\n",
    "Esta base é bem similar à base de perguntas, em estrutura: temos uma coluna para as perguntas, e outra coluna para os respectivos intents. Sua construção, no entanto, foi um pouco mais livre, pois não nos preocupamos em balancear as classes: simplesmente fomos coletando as perguntas que mais aparecem nos marketplaces, e as classificando.\n",
    "\n",
    "Uma distinção importante é que, como veremos, nesta base de testes também temos perguntas com mais de um intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:28.043789Z",
     "start_time": "2020-05-03T20:42:27.838128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intents das perguntas na base:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Entrega                            163\n",
       "Cor                                 96\n",
       "Dimensão                            75\n",
       "Disponibilidade                     67\n",
       "Estado                              44\n",
       "Voltagem                            42\n",
       "Meios de pagamento                  31\n",
       "Acessórios                          25\n",
       "Nota Fiscal                         14\n",
       "Capacidade                           9\n",
       "Garantia                             5\n",
       "Bateria                              5\n",
       "Estado | Nota Fiscal                 4\n",
       "Disponibilidade | Entrega            3\n",
       "Disponibilidade | Estado             2\n",
       "Estado | Nota Fiscal | Garantia      2\n",
       "Nota Fiscal | Garantia               2\n",
       "Estado | Voltagem                    2\n",
       "Disponibilidade | Nota Fiscal        2\n",
       "Meios de pagamento | Entrega         1\n",
       "Entrega | Cor                        1\n",
       "Estado | Garantia                    1\n",
       "Estado | Nota Fiscal | Entrega       1\n",
       "Disponibilidade | Cor                1\n",
       "Acessórios | Bateria                 1\n",
       "Estado | Estado                      1\n",
       "Name: intent, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"base_teste_perguntas.csv\")\n",
    "\n",
    "print(\"\\nIntents das perguntas na base:\")\n",
    "display(df_test[\"intent\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mencionamos, não nos preocupamos com o balanço dos intents, e também incluímos perguntas com mais de um intent. Explicaremos a seguir como o modelo pode ser capaz de tratar estes casos, mas, a princípio, já é de se esperar que a performance do modelo nesta base de teste será menor que a que observamos na base de validação, pois _não treinamos o modelo com perguntas de mais de um intent_. \n",
    "\n",
    "Mesmo assim, como explicaremos a seguir, alteramos o modelo para fazer previsões também para estes casos, embora seja de se esperar que a performance para perguntas com mais de um intent não será tão boa quanto a performance nas perguntas de apenas um intent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos a seguir duas funções para a análise da performance do modelo com os dados da base de teste.\n",
    "\n",
    "__previsao():__ esta função é muitíssimo importante, pois é aqui que definimos como o momodelo pode fazer previsões de mais de um intent. O processo é o seguinte:\n",
    "\n",
    "- pré-processo a pergunta de input e a vetorizo;\n",
    "- defino qual é a chance do modelo acertar a classe chutando aleatoriamente (que é 1/12);\n",
    "- uso o modelo para prever qual é a probabilidade da pergunta ser pertencente a cada uma das 12 classes (isso  é um vetor de 12 componentes, com um numero entre 0 e 1 em cada componente, que é a probabilidade respectiva de cada classe);\n",
    "- destas probabilidades, eu seleciono quais são as probabilidades que são maiores que um desvio de duas vezes a chance do modelo acertar se chutar da maior probabilidade. Estas probabilidades são muito provavelmente a(s) classe(s) corretas. Note que é possível que apenas uma probabilidade seja selecionada (apenas a probabilidade máxima), mas pode ser que mais de uma sejam selecionadas (que é justamente o caso de perguntas de mais um intent!\n",
    "\t- este ponto é muitíssimo importante, então vale a pena explicá-lo em outras palavras: nesta etapa, a maior entre as 12 probabilidades SEMPRE será selecionada. Digamos que seu valor seja P. Agora, houver outras probabilidades cujo valor é MAIOR que P - 2*(1/12), nós TAMBÉM retornamos estas outras probabilidades!\n",
    "- por fim, destas probabilidades que retornamos no passo anterior, tomamos APENAS as que forem maior do que 2*(1/12) como previsões válidas, e aí guardamos os respectivos intents!\n",
    "\t- note que pode ser que nenhuma probabilidade, nem a máxima, seja maior que 2 vezes a chance do modelo acertar aleatoriamente. Estes são justamente os casos em que a o modelo \"não entendeu a pergunta\"! Nestes casos, o modelo não responde nada: ele simplesmente fala que não entendeu a pergunta, e que vai encaminhá-la para o vendedor. Esperamos que sejam poucas as perguntas em que isso ocorre (e vamos mensurar isso a seguir nos analytics!)\n",
    "\n",
    "Por fim, a função retorna o(s) intent(s), e não exatamente a resposta respectiva (pois aqui não estamos preocupados ainda com a resposta, esta usaremos na interface gráfica!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T21:04:39.495731Z",
     "start_time": "2020-05-03T21:04:39.483333Z"
    }
   },
   "outputs": [],
   "source": [
    "def previsao(x):\n",
    "    \n",
    "    #pego o modelo\n",
    "    model = fit\n",
    "    \n",
    "    #esse é o fator de threshold, th1 vezes a aleatoriedade\n",
    "    th1=2.5\n",
    "\n",
    "    #aqui eu pre-processo a pergunta\n",
    "    question = pre_proc(x)\n",
    "    #e aqui faço o one-hot encoding (uma unica pergunta)\n",
    "    X = cv.transform([question]).toarray()\n",
    "\n",
    "    #aqui o modelo retorna quais as probabilidades de cada classe\n",
    "    #(o retorno é um vetor de 12 componentes, com um numero entre 0\n",
    "    #e 1, que é a probabilidade respectiva de cada classe)\n",
    "    class_probs = model.predict_proba(X)\n",
    "    \n",
    "    #essa é a chance do modelo acertar se chutar aleatoriamente\n",
    "    th2 = 1/len(model.classes_)\n",
    "\n",
    "    #aqui eu pego quais são as probabilidades que são maiores\n",
    "    #que um desvio de th1*chance_aleatoria da maior probabilidade\n",
    "    class_max = class_probs[class_probs > class_probs.max() - th1*th2]\n",
    "\n",
    "    #aqui eu realente pego as respostas (nesse caso, só intents)\n",
    "    #e ponho numa lista\n",
    "    resposta = []\n",
    "    nao_sei = True\n",
    "    for prob in class_max:\n",
    "        #se a probasilidade for maior que th1*chance_aleatoria\n",
    "        if prob > th1*th2:\n",
    "            y_pred = model.classes_[class_probs.squeeze().tolist().index(prob)]\n",
    "            resposta.append(y_pred)\n",
    "            nao_sei = False\n",
    "            \n",
    "    resposta = \" | \".join(resposta)\n",
    "            \n",
    "    #pro caso de nenhuma probabilidade ser maior que th1*chance_aleatoria\n",
    "    #esses são os casos, MUITO IMPORTANTES, em que o robo nao consegue\n",
    "    #entender a pergunta, e acaba encaminhando-a pro vendedor mesmo\n",
    "    if nao_sei:\n",
    "        resposta = \"Não sei\"\n",
    "\n",
    "    return resposta\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__analysis()__: esta função simplesmente calcula os acertos e erros da previsão do modelo. Para os casos de perguntas com mais de um intent, nós contamos como acerto se o modelo acertar um intent a menos do que o número total de intents na pergunta. Julgamos que este é um critério justo, pois no mundo real, caso um possível comprador faça uma pergunta com dois intents e apenas um deles for respondido corretamente, é muito provável que o possível comprador simplesmente refaça a pergunta mais uma vez, mas com apenas o intent que não foi respondido, em cujo caso o modelo funcionará muito bem. Como as respostas serão dadas de forma virtualmente instantânea, não vemos problemas com essa metodologia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:28.685280Z",
     "start_time": "2020-05-03T20:42:28.120192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance do modelo na base de teste:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "acertou    0.883333\n",
       "errou      0.116667\n",
       "Name: analise, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analysis(row):\n",
    "\n",
    "    real = row[\"intent\"]\n",
    "    previsto = row[\"previsto\"]\n",
    "    \n",
    "    real = real.lower().split(\" | \")\n",
    "    previsto = previsto.lower().split(\" | \")\n",
    "    \n",
    "    score = 0\n",
    "    for item in previsto:\n",
    "        if item in real:\n",
    "            score += 1\n",
    "            \n",
    "    if len(real) > 1:\n",
    "        if score >= len(real)-1:\n",
    "            ans = \"acertou\"\n",
    "        else:\n",
    "            ans = \"errou\"\n",
    "    else:\n",
    "        if score == len(real):\n",
    "            ans = \"acertou\"\n",
    "        else:\n",
    "            ans = \"errou\"\n",
    "        \n",
    "    return ans\n",
    "\n",
    "print(\"\\nPerformance do modelo na base de teste:\")\n",
    "df_test_results = df_test.copy()\n",
    "df_test_results[\"previsto\"] = df_test_results[\"pergunta\"].apply(lambda x: previsao(x))\n",
    "df_test_results[\"analise\"] = df_test_results.apply(lambda row: analysis(row), axis=1)\n",
    "display(df_test_results[\"analise\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperado e discutido anteriormente, a performance na base de testes realmente é um pouco menor do que a observada com a base de validação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequência de intents\n",
    "\n",
    "Conforme descrevemos, construímos a base para que esta reflita o fluxo esperado de perguntas! E isso é o que o primeiro gráfico mostra: quais as perguntas que mais aparecem? Aí, por exemplo, se houver uma grande quantidade de perguntas sobre as cores disponíveis da cafeteira, isso será reportado nos analytics, e a Olist ou os vendedores podem tomar essa informação como um alerta: será que as cores da cafeteira não estão bem descritas e bem evidentes no anúncio? Talvez valha a pena reformulá-lo... \n",
    "\n",
    "Desta forma, esta base de teste realmente simula as perguntas que foram recebidas após o modelo ter sido posto em produção, o que pode ser visualizado a seguir:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:28.915064Z",
     "start_time": "2020-05-03T20:42:24.225Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "data = df_test[\"intent\"].value_counts(normalize=True)\n",
    "\n",
    "g = sns.barplot(x = data.index.tolist(), y = data.values.tolist())\n",
    "plt.title(\"Frequência relativa de intents na base de teste\")\n",
    "plt.xlabel(\"Intents\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Frequência relativa\")\n",
    "plt.show()\n",
    "\n",
    "ax=g\n",
    "#annotate axis = seaborn axis\n",
    "for p in ax.patches:\n",
    "             ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
    "                 textcoords='offset points')\n",
    "_ = g.set_ylim(0, 1.2) #To make space for the annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoramento do modelo\n",
    "\n",
    "O segundo analytics que mostramos funciona mais como uma percepção sobre a performance do modelo na base de testes: quantas perguntas ele errou, e de quais classes? Que perguntas ele não respondeu? Estas informações são muito importantes como um acompanhamento da performance do modelo conforme o tempo passa, deixando evidente de forma visual caso haja a necessidade de retreinamento do modelo (o que naturalmente acontece com o passar do tempo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:28.916320Z",
     "start_time": "2020-05-03T20:42:24.228Z"
    }
   },
   "outputs": [],
   "source": [
    "#aqui calculamos rapidamente quantas perguntas, do total, o modelo não entendeu e precisou encaminhar pro vendedor:\n",
    "\n",
    "n_nao_sei = df_test_results[df_test_results[\"previsto\"] == \"Não sei\"].shape[0]\n",
    "n_total = df_test_results.shape[0]\n",
    "\n",
    "print(\"\\nA base de teste tem\", n_total, \"perguntas.\")\n",
    "print(\"\\nDestas, o modelo NÃO consegui responder\", n_nao_sei, \"perguntas.\")\n",
    "print(\"\\nIsto representa \" + str(round((n_nao_sei/n_total)*100, 2))  + \"% do total!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T20:42:28.917522Z",
     "start_time": "2020-05-03T20:42:24.231Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in df_test_results[\"intent\"].unique().tolist():\n",
    "    \n",
    "    print(\"Intent:\", item)\n",
    "    \n",
    "    print(\"\\nDe todas as perguntas, as frequencias de acerto e erro são:\")\n",
    "    aux = df_test_results[df_test_results[\"intent\"] == item]\n",
    "    count = aux[\"analise\"].value_counts(normalize=True)\n",
    "    display(count)\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    g = sns.barplot(x = count.index.tolist(), y = count.values.tolist())\n",
    "    plt.title(\"Frequência de\\nacertos e erros\\ndo intent \" + item)\n",
    "    plt.xlabel(\"Intents\")\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Frequência relativa\")\n",
    "    \n",
    "    ax=g\n",
    "    #annotate axis = seaborn axis\n",
    "    for p in ax.patches:\n",
    "                 ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
    "                     textcoords='offset points')\n",
    "    _ = g.set_ylim(0, 1.2) #To make space for the annotations\n",
    "\n",
    "    \n",
    "    print(\"\\nDe todas as perguntas QUE FORAM RESPONDIDAS (i.e., tirando as que ele respondeu 'Não sei', as frequencias de acerto e erro são:\")\n",
    "    aux = aux[aux[\"previsto\"] != \"Não sei\"]\n",
    "    count = aux[\"analise\"].value_counts(normalize=True)\n",
    "    display(count)\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    g=sns.barplot(x = count.index.tolist(), y = count.values.tolist())\n",
    "    plt.title(\"Frequência de\\nacertos e erros\\ndo intent \" + item + \",\\nentre perguntas\\nefetivamente respondidas\")\n",
    "    plt.xlabel(\"Intents\")\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Frequência relativa\")\n",
    "    \n",
    "    ax=g\n",
    "    #annotate axis = seaborn axis\n",
    "    for p in ax.patches:\n",
    "                 ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
    "                     textcoords='offset points')\n",
    "    _ = g.set_ylim(0, 1.2) #To make space for the annotations\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"\\n###############################################\")\n",
    "    print(\"###############################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 7: GUI\n",
    "\n",
    "Por fim, construímos uma interface gráfica bem simples para ilustrar o funcionamento do robô e simular como seria o robô em produção, isto é: \n",
    "\n",
    "- O potencial comprador procura por um produto (dentre os 10 que temos cadastrados);\n",
    "- O produto aparece pro potencia comprador (aqui exibimos apenas uma imagem ilustrativa);\n",
    "- O potencial comprador tem um campo para fazer alguma pergunta;\n",
    "- Imediatamente após enviar a pergunta, o robô elabora a resposta e a exibe, contendo sempre detalhes das informações cadastradas na base de produtos.\n",
    "\n",
    "Ressaltamos que nossa solução dispensa completamente a necessidade de uma interface gráfica: nosso robô estaria implantado na plataforma da olist, de modo que todo o processamento seria feito na própria plataforma, segundo o fluxo que descrevemos anteriormente. Assim, fizemos a interface gráfica apenas para fins de apresentação e demonstração da usabilidade de nossa solução no pitch.\n",
    "\n",
    "No código da interface, temos a função \"bot()\", que é muito similar à \"previsao()\", que descrevemos anteriormente. Esta função é muitissimo importante, pois é nela que o modelo retorna os intents mais prováveis, conforme critério que já discutimos. A único diferença é que aqui a função realmente retorna a resposta (note que a função \"resposta_bot()\" é chamada!).\n",
    "\n",
    "Vejamos a interface em funcionamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T21:43:16.725451Z",
     "start_time": "2020-05-03T21:33:53.608657Z"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def coletar_produto(produto):\n",
    "    \n",
    "    global product_global\n",
    "    \n",
    "    foto = tk.PhotoImage(file=\"./imagens/\"+produto+\".png\")\n",
    "    label_imagem = tk.Label(frame_imagem, image=foto)\n",
    "    label_imagem.image = foto\n",
    "    label_imagem.place(relheight=1, relwidth=1)\n",
    "    \n",
    "    if produto == \"celular\":\n",
    "        product_global = 'Samsung Galaxy J2'\n",
    "    elif produto == \"controle\":\n",
    "        product_global = 'Controle joystick Sony Dualshock 4 500 million limited edition'\n",
    "    elif produto == \"forno\":\n",
    "        product_global = 'Forno Elétrico Inox Premium Lenoxx- Pfo 303'\n",
    "\n",
    "    \n",
    "################################################\n",
    "\n",
    "def coletar_pergunta(question):\n",
    "    \n",
    "    ans = bot(th1=2.5, pergunta=question, produto=product_global) \n",
    "    \n",
    "    texto_resposta = tk.Label(frame_resposta, bg='white', text=ans, anchor='nw', font=(\"Courier\", 15), justify=\"left\")\n",
    "    texto_resposta.place(relheight=1, relwidth=1)\n",
    "\n",
    "    return pergunta\n",
    "    \n",
    "################################################\n",
    "\n",
    "def callback(sv):\n",
    "    global produto\n",
    "    produto = (sv.get())\n",
    "    \n",
    "################################################\n",
    "\n",
    "def bot(th1=2.5, pergunta=\"\", produto=\"\"):\n",
    "\n",
    "    model = fit\n",
    "    \n",
    "    pergunta_pp = pre_proc(pergunta)\n",
    "\n",
    "    X = cv.transform([pergunta_pp]).toarray()\n",
    "\n",
    "    class_probs = model.predict_proba(X)\n",
    "\n",
    "    th2 = 1/len(model.classes_)\n",
    "\n",
    "    class_max = class_probs[class_probs > class_probs.max() - th1*th2]\n",
    "\n",
    "    resposta = []\n",
    "    nao_sei = True\n",
    "    for prob in class_max:\n",
    "        if prob > th1*th2:\n",
    "            y_pred = model.classes_[class_probs.squeeze().tolist().index(prob)]\n",
    "            resposta.append(respostas_bot(prod = base_de_produtos, intent = y_pred, produto = produto))\n",
    "            nao_sei = False\n",
    "            \n",
    "    resposta2 = []\n",
    "    check = False\n",
    "    for item in resposta:\n",
    "        if check:\n",
    "            a = item.replace(\"Olá! \", \"\")\n",
    "        else:\n",
    "            a = item\n",
    "        if \"Olá\" in item:\n",
    "            check = True\n",
    "        resposta2.append(a)\n",
    "    \n",
    "    resposta = \"\\n\".join(resposta2)\n",
    "\n",
    "    if nao_sei:\n",
    "        resposta = \"Não entendi a pergunta. Vou direcioná-la ao vendedor, e ele te responderá o mais rápido possível!\" \n",
    "        \n",
    "    return(resposta)\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "# configuração inicial\n",
    "\n",
    "janela_principal = tk.Tk() # single window\n",
    "janela_principal.title('www.marketplace.com.br')\n",
    "canvas = tk.Canvas(janela_principal, height=1000, width=1000) # tamanho da janela ao abrir\n",
    "canvas.pack()\n",
    "\n",
    "# cabeçalhos e bordas\n",
    "\n",
    "frame_cabeçalho = tk.Frame(janela_principal, bg='#003ec5')\n",
    "frame_cabeçalho.place(relwidth=1, relheight=0.10)\n",
    "\n",
    "\n",
    "frame_produto = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_produto.place(relwidth=0.3, relheight=0.05, relx=0.1, rely=0.173)\n",
    "frame_imagem = tk.Frame(janela_principal)\n",
    "frame_imagem.place(relwidth=0.3, relheight=0.38, relx=0.073, rely=0.235)\n",
    "\n",
    "\n",
    "frame_pergunta = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_pergunta.place(relwidth=0.6, relheight=0.1, relx=0.1, rely=0.67)\n",
    "frame_resposta = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_resposta.place(relwidth=0.6, relheight=0.1, relx=0.1, rely=0.85)\n",
    "\n",
    "# botões\n",
    "\n",
    "botao_produto = tk.Button(janela_principal, text='OK', bg='#edad00', fg='white', font='Helvetica 12 bold', command=lambda: coletar_produto(entrada_produto.get()))\n",
    "botao_produto.place(relheight=0.05, relwidth=0.05, relx=0.41, rely=0.173)\n",
    "botao_pergunta = tk.Button(janela_principal, text='Enviar Pergunta', bg='#edad00', fg='white', font='Helvetica 12 bold', command=lambda: coletar_pergunta(entrada_pergunta.get()))\n",
    "botao_pergunta.place(relheight=0.08, relwidth=0.15, rely=0.681, relx=0.723)\n",
    "\n",
    "# labels\n",
    "label_titulo = tk.Label(janela_principal, text='oList', fg='white', bg='#003ec5', font='Courier 30 bold')\n",
    "label_titulo.place(relheight=0.05, width=118, relx=0.1, rely=0.035)\n",
    "label_produto = tk.Label(janela_principal, text='Produto', font=40, fg='#24221d', anchor='w')\n",
    "label_produto.place(relheight=0.05, width=100, relx=0.1, rely=0.12)\n",
    "label_pergunta = tk.Label(janela_principal, text='Pergunte ao vendedor', font=40, fg='#24221d', anchor='w')\n",
    "label_pergunta.place(relheight=0.05, width=200, relx=0.1, rely=0.615)\n",
    "\n",
    "\n",
    "label_resposta = tk.Label(janela_principal, text='Resposta', font=40, fg='#24221d', anchor='w')\n",
    "label_resposta.place(relheight=0.05, width=200, relx=0.1, rely=0.795)\n",
    "\n",
    "texto_resposta = tk.Label(frame_resposta, bg='white', text='', anchor='nw', font=(\"Courier\", 15))\n",
    "texto_resposta.place(relheight=1, relwidth=1)\n",
    "\n",
    "# entries\n",
    "\n",
    "entrada_produto = tk.Entry(frame_produto, font=40, bg='white')\n",
    "entrada_produto.place(relheight=1, relwidth=1)\n",
    "entrada_pergunta = tk.Entry(frame_pergunta, font=100, bg='white')\n",
    "entrada_pergunta.place(relheight=1, relwidth=1)\n",
    "\n",
    "\n",
    "janela_principal.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
