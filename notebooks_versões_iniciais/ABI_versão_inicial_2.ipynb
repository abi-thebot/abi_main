{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABI - versão inicial 2\n",
    "\n",
    "(Descrição, ao finalizar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 0: importação de bibliotecas\n",
    "\n",
    "Usaremos as seguintes bibliotecas (TODO: adicionar links para a documentação):\n",
    "\n",
    "- Numpy: para vetorização de dados;\n",
    "- Pandas: para manipulação de base dados;\n",
    "- NLTK: para ferramentas de NLP;\n",
    "- Re: para processamento de regex;\n",
    "- ast: pra trasnformar string em dicionário;\n",
    "- Scikitlearn: para modelagem estatística e machine learning;\n",
    "- TensorFlow: framework de redes neurais e deep learning;\n",
    "- Keras: API de alto nível para o TensorFlow;\n",
    "- Matplotlib: para plots e visualizações\n",
    "- Seaborn: para plotagem estatística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando de principais bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:55.807487Z",
     "start_time": "2020-05-02T16:22:54.402471Z"
    }
   },
   "outputs": [],
   "source": [
    "#processamento de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#regex\n",
    "import re\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('rslp')\n",
    "\n",
    "#dataviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#random\n",
    "import random\n",
    "#pra termos resultados mais fixos\n",
    "\n",
    "#pra tirar acentos\n",
    "import unidecode\n",
    "\n",
    "#pra transformar string em dict\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: leitura de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo a base de perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:55.840123Z",
     "start_time": "2020-05-02T16:22:55.809700Z"
    }
   },
   "outputs": [],
   "source": [
    "#numero de perguntas pra cada intent\n",
    "n = 100\n",
    "\n",
    "df_q = pd.read_csv(\"base_treino_\" + str(n) + \".csv\")\n",
    "\n",
    "#é bom dar uma misturada...\n",
    "df_q = df_q.sample(frac=1, random_state = 42).reset_index(drop=True)\n",
    " \n",
    "#essa é a base desbalanceada\n",
    "df_desbalanc = df_q[~df_q[\"intent\"].isin(df_q[\"intent\"].value_counts()[df_q[\"intent\"].value_counts() == n].index.tolist())]\n",
    "\n",
    "#essa é a base balanceada (vou manter o mesmo nome)\n",
    "df_q = df_q[df_q[\"intent\"].isin(df_q[\"intent\"].value_counts()[df_q[\"intent\"].value_counts() == n].index.tolist())]\n",
    "    \n",
    "if (~df_q[\"intent\"].value_counts().values == n).sum() == 0:\n",
    "    print(\"Bases balanceada e desbalanceadas separadas com sucesso!\")\n",
    "    display(df_q.head())\n",
    "else:\n",
    "    print(\"Erro... Olha o código!\")\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:55.984179Z",
     "start_time": "2020-05-02T16:22:55.841607Z"
    }
   },
   "outputs": [],
   "source": [
    "df_q.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.078857Z",
     "start_time": "2020-05-02T16:22:55.987429Z"
    }
   },
   "outputs": [],
   "source": [
    "perguntas = df_q.iloc[:,1]\n",
    "print(\"\\nTemos\", len(perguntas), \"perguntas na base.\\nAs perguntas estão distribuídas em diferentes intents:\\n\")\n",
    "\n",
    "intents = df_q.iloc[:,0]\n",
    "print(\"Temos\", len(intents.unique()), \"intents na base, com as respectivas quantidades de perguntas\",\n",
    "                                      \"(que idealmente devem ser balanceadas entre os intents):\")\n",
    "display(intents.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do corpus a partir das perguntas da base de treino\n",
    "\n",
    "Etapas de pré-processamento (todas são discutíveis):\n",
    "\n",
    "- limpeza do texto: retiramos números e pontuação;\n",
    "- deixamos todo o texto em minúsculas;\n",
    "- aplicamos stemming. Temos duas opções de stemmers:\n",
    "    - RSLP Stemmer: http://www.inf.ufrgs.br/~viviane/rslp/index.htm\n",
    "    - Snowball (Porter2): https://snowballstem.org/\n",
    "- retiramos as stopwords das perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.373014Z",
     "start_time": "2020-05-02T16:22:56.082594Z"
    }
   },
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stpwrds = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "#essa é a função de pre-processamento\n",
    "def pre_proc(pergunta, stpwrds=stpwrds):\n",
    "    \n",
    "    #vamos jogar fora tudo que não são letras minusculas e maiusculas (incluido acentuações)\n",
    "    #vou manter também apenas os numeros 0,1,2, pra poder captar 110 e 220\n",
    "    pergunta = re.sub(\"[^a-zA-ZáàâãéèêíïóôõöúçñÁÀÂÃÉÈÍÏÓÔÕÖÚÇÑ0-2]\", \" \", pergunta)\n",
    "\n",
    "    #deixa tudo minuscula\n",
    "    pergunta = pergunta.lower()\n",
    "\n",
    "    #tonkeniza\n",
    "    pergunta = pergunta.split()\n",
    "\n",
    "    #stemmer SB\n",
    "    stemmer = nltk.stem.SnowballStemmer('portuguese')\n",
    "        \n",
    "    #tira stopwprds. tora acentps e aplica o stemmer\n",
    "    pergunta = [stemmer.stem(unidecode.unidecode(word)) for word in pergunta if word not in set(stpwrds)]\n",
    "\n",
    "    #refaz a string\n",
    "    pergunta = \" \".join(pergunta)\n",
    "\n",
    "    return pergunta\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for item in perguntas:\n",
    "\n",
    "    pergunta = pre_proc(item, stpwrds)\n",
    "\n",
    "    #adiciona ao corpus\n",
    "    corpus.append(pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.377864Z",
     "start_time": "2020-05-02T16:22:56.375007Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"\\nComparação entre a pergunta original e a versão pré-processada da pergunta no corpus:\\n\")\n",
    "\n",
    "# for i in range(len(perguntas)):\n",
    "#     print(perguntas[i], \"|\", corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra começar, vamos fazer um pequeno estudo quanto ao vocabulário do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.723161Z",
     "start_time": "2020-05-02T16:22:56.380000Z"
    }
   },
   "outputs": [],
   "source": [
    "#só pra ter uma ideia do vocabulário, vamos fazer uma lista de listas com o formato:\n",
    "#vocabulario[i] = [palavra, numero_de_aparicoes_no_corpus]\n",
    "\n",
    "vocabulario = []\n",
    "for pergunta in corpus:\n",
    "    for palavra in pergunta.split():\n",
    "        #não queremos palavras de uma única letra (pode acontecer devido ao stemming...)\n",
    "        if len(palavra) > 1:\n",
    "            if palavra not in [x[0] for x in vocabulario]:\n",
    "                vocabulario.append([palavra, 1])\n",
    "            else:\n",
    "                vocabulario[[x[0] for x in vocabulario].index(palavra)][1] += 1\n",
    "            \n",
    "print(\"\\nO vocabulário é formado por\", len(vocabulario), \"palavras!\")\n",
    "\n",
    "#a partir do vocabulário, crio um dataframe com a contagem\n",
    "vocab_count = pd.DataFrame({\"palavra\": [],\n",
    "                           \"count\": []})\n",
    "\n",
    "vocab_count[\"palavra\"] = pd.Series(vocabulario).apply(lambda x: x[0])\n",
    "vocab_count[\"count\"] = pd.Series(vocabulario).apply(lambda x: x[1])\n",
    "vocab_count = vocab_count.sort_values(\"count\", ascending=False)\n",
    "\n",
    "print(\"\\nTemos a seguir as 10 mais comuns, com as respectivas contagens:\")\n",
    "display(vocab_count.head(10))\n",
    "\n",
    "raras = vocab_count[vocab_count[\"count\"] == 1]\n",
    "prop_raras = raras.shape[0]/vocab_count.shape[0]\n",
    "print(\"\\nA quantidade de palavras com apenas uma aparição no corpus (palavras raras)\\né de \" + str(raras.shape[0]) +\n",
    "     \", o que equivale a\", str(round(100*(prop_raras), 2)) + \"% da base!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO: (maybe): pequena análise exploratória da frequencia relativa das palavras__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazer o bag of words propriamente, vamos usar o CountVectorizer do sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.751753Z",
     "start_time": "2020-05-02T16:22:56.725219Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#o max_feacutres imita o tamanho do vocabulario.. Não sei o quanto é interessante\n",
    "# cv = CountVectorizer(max_features = 1500)\n",
    "cv = CountVectorizer()\n",
    "\n",
    "#features\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "#target\n",
    "# y = intents_num\n",
    "y = intents.values\n",
    "\n",
    "#validação\n",
    "if X.shape[1] == vocab_count.shape[0] and X.shape[0] == len(perguntas):\n",
    "    print(\"As dimensões da matrix de features estão corretas!\")\n",
    "    print(\"\\nBag of words feito com sucesso!\")\n",
    "else:\n",
    "    print(\"As dimensões não batem! Reveja o código!\")\n",
    "    for item in [x[0] for x in vocabulario]:\n",
    "        if item not in list(cv.vocabulary_.keys()):\n",
    "            print(item)\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: modelagem preditiva\n",
    "\n",
    "Testaremos agora diferentes modelos para a previsão dos intents com base nas perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.885308Z",
     "start_time": "2020-05-02T16:22:56.753601Z"
    }
   },
   "outputs": [],
   "source": [
    "#train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#avaliação de performanace\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:22:56.960881Z",
     "start_time": "2020-05-02T16:22:56.887464Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify=y)\n",
    "\n",
    "\n",
    "print(\"Check de balanço do train-test split:\")\n",
    "display(pd.Series(y_train).value_counts())\n",
    "display(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T16:33:30.541524Z",
     "start_time": "2020-05-02T16:33:27.945480Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#############################################################################################\n",
    "#############################################################################################\n",
    "############################################################################################# \n",
    "######################################## MODELOS\n",
    "\n",
    "#Modelos:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#instanciando os modelos\n",
    "modelos = {\"gnb\": GaussianNB(),\n",
    "           \"mnb\": MultinomialNB(),\n",
    "           \"logit\": LogisticRegression(solver=\"lbfgs\", multi_class=\"multinomial\", random_state = 42),\n",
    "           \"svm\": SVC(decision_function_shape='ovo', gamma=\"auto\", kernel=\"linear\", C=10, random_state = 42),\n",
    "           \"rf\": RandomForestClassifier(n_estimators=300, max_depth=None, random_state = 42)}\n",
    "\n",
    "#nesta lista eu vou colocar todos os modelos que eu fitar em cada modo, com as respectivas indicações\n",
    "#formato da lista modelos_fitados:\n",
    "#[[nome_do_modelo, modelos_fitados]*numero_de_modelos]\n",
    "modelos_fitados = []\n",
    "\n",
    "#nessa lista eu vou guardar apenas os melhores modelos de cada modo\n",
    "#formato da lista melhores_modelos_fitados\n",
    "#[[nome_do_melhor_modelo, weighted_f1_do_melhor_modelo, melhor_modelos_fitados]*1]\n",
    "melhores_modelos_fitados = []\n",
    "\n",
    "#inicializa o melhor f1 como zero\n",
    "melhor_f1 = 0\n",
    "for modelo in list(modelos.keys()):\n",
    "\n",
    "    print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~ | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "\n",
    "    print(\"Modelo:\", modelo)\n",
    "    print(\"\\nParâmetros:\", modelos[modelo])\n",
    "\n",
    "    fit = modelos[modelo].fit(X_train, y_train)\n",
    "    y_pred = fit.predict(X_test)\n",
    "\n",
    "    print(\"\\nAvaliação:\\n\")\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    #salva o modelo fitado na forma modelos_fitados[i] = [nome_do_modelo, modelos_fitados]\n",
    "    modelos_fitados.append([modelo, fit])\n",
    "\n",
    "    #vendo qual é o melhnor modelo\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1 = cr[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "    if f1 > melhor_f1:\n",
    "        melhor_f1 = f1\n",
    "        melhor = modelo\n",
    "        melhor_fit = fit\n",
    "\n",
    "print(\"\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "print(\"\\nModelo com maior weighted f1:\", melhor, \", com weighted f1 de\", melhor_f1)\n",
    "\n",
    "print(\"\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")  \n",
    "\n",
    "melhores_modelos_fitados.append([melhor, melhor_f1, melhor_fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T04:16:45.279122Z",
     "start_time": "2020-05-03T04:16:45.254420Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_random_seed(42)\n",
    "\n",
    "#cria modelo\n",
    "def nn_model(optimizer=\"adam\", alpha=0.01):\n",
    "\n",
    "    ###################### ARQUITETURA DA REDE NEURAL ######################\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(intents.unique()), activation='softmax'))\n",
    "\n",
    "    ###################### OPTIMIZER ######################\n",
    "\n",
    "    if optimizer == \"adam\":\n",
    "        opt = keras.optimizers.Adam(lr=alpha)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        opt = keras.optimizers.RMSprop(lr=alpha)\n",
    "    elif optimizer == \"sgd\":\n",
    "        opt = keras.optimizers.SGD(lr=alpha, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    ###################### COMPILAÇÃO DO MODELO ######################\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "#dicionario de modelos\n",
    "modelos_nn = {}\n",
    "\n",
    "#lista de parâmetros pros diferentes modelos\n",
    "#formato: [optimizer, alpha(lr), n_epochs, batch_size, nome_do_modelo]\n",
    "parametros = [\n",
    "                [\"rmsprop\", 0.001, 10, 10, \"opt=rmsprop | lr=0.001 | n_epochs=10 | batch_size=10\"],\n",
    "                [\"rmsprop\", 0.001, 150, 10, \"opt=rmsprop | lr=0.001 | n_epochs=100 | batch_size=10\"],\n",
    "            ]\n",
    "\n",
    "for item in parametros:\n",
    "    \n",
    "    modelos_nn[item[-1]] = KerasClassifier(build_fn = nn_model, optimizer = item[0], alpha = item[1], epochs=item[2], batch_size=item[3], verbose=0)\n",
    "\n",
    "\n",
    "#nesta lista eu vou colocar todos os modelos que eu fitar em cada modo, com as respectivas indicações\n",
    "#formato da lista modelos_fitados:\n",
    "#[[nome_do_modelo, modelos_fitados]*numero_de_modelos]\n",
    "modelos_fitados_nn = []\n",
    "\n",
    "#nessa lista eu vou guardar apenas os melhores modelos de cada modo\n",
    "#formato da lista melhores_modelos_fitados\n",
    "#[[nome_do_melhor_modelo, weighted_f1_do_melhor_modelo, melhor_modelos_fitados]*1]\n",
    "melhores_modelos_fitados_nn = []\n",
    "\n",
    "#inicializa o melhor f1 como zero\n",
    "melhor_f1 = 0\n",
    "for modelo in list(modelos_nn.keys()):\n",
    "\n",
    "    print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~ | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~ | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "\n",
    "    print(\"Modelo:\", modelo)\n",
    "    print(\"\\nParâmetros:\", modelos_nn[modelo])\n",
    "\n",
    "    modelos_nn[modelo].fit(X_train, y_train)\n",
    "    y_pred = modelos_nn[modelo].predict(X_test)\n",
    "\n",
    "    print(\"\\nAvaliação:\\n\")\n",
    "    # print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))   \n",
    "\n",
    "    #salva o modelo fitado na forma modelos_fitados[i] = [nome_do_modelo, modelos_fitados]\n",
    "    modelos_fitados_nn.append([modelo, modelos_nn[modelo]])\n",
    "\n",
    "    #vendo qual é o melhnor modelo\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    f1 = cr[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "    if f1 > melhor_f1:\n",
    "        melhor_f1 = f1\n",
    "        melhor = modelo\n",
    "        melhor_fit = modelos_nn[modelo]\n",
    "\n",
    "print(\"\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "print(\"\\nModelo com maior weighted f1:\", melhor, \", com weighted f1 de\", melhor_f1)\n",
    "\n",
    "print(\"\\n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\n\")  \n",
    "\n",
    "melhores_modelos_fitados_nn.append([melhor, melhor_f1, melhor_fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: ligação com a base de produtos\n",
    "\n",
    "Agora vamos ler a base de produto e implementar a estrutura de comunicação do modelo com ela pra criarmos as respostas do bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alterações:\n",
    "- colocar o parcelamento da forma de pagamento;\n",
    "- em acessórios, se tiver mais de um acessório que acompanha, coloca em plural a chave do dict;\n",
    "- adicionar produtos usados em \"estado\" \n",
    "- deixar as chaves do dict com acentos, etc\n",
    "- cores: nao deixar a ultima ser uma que nao tá disponivel\n",
    "- \"desconto\" --> \"com possibilidade de desconto\"; \"cartao_credito\" --> \"cartão de crédito\"\n",
    "- nao deixa uma forma de pagamento nao disponivel como ultima tbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:28:05.881322Z",
     "start_time": "2020-05-02T21:28:05.745031Z"
    }
   },
   "outputs": [],
   "source": [
    "base_de_produtos = pd.read_csv(\"base_produto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:28:06.495357Z",
     "start_time": "2020-05-02T21:28:06.435992Z"
    }
   },
   "outputs": [],
   "source": [
    "# essa resposta constrói a resposta final de acordo com cada intent.\n",
    "# os argumentos são: \n",
    "# o dicionario de intents dic_intent do respectivo produto; \n",
    "# o dicionario de respostas iniciais respostas_inicio; \n",
    "# o intent(que é output do modelo)\n",
    "def resposta_especificas(dic_intent, intent):\n",
    "    \n",
    "    #dicionario com a base das respostas\n",
    "    respostas_inicio = {'Acessórios': 'Olá! O(s) seguinte(s) item(s) vem junto com o produto: ', \n",
    "                         'Bateria': 'Olá! A bateria do produto tem as seguintes características: ', \n",
    "                         'Capacidade': 'Olá! O produto tem as seguintes especificações de capacidade: ', \n",
    "                         'Cor': 'Olá! Temos as seguintes cores disponíveis: ', \n",
    "                         'Dimensão': 'Olá! As dimensões do produto são: ', \n",
    "                         'Disponibilidade': 'Olá! ',\n",
    "                         'Entrega': 'Olá! ',\n",
    "                         'Estado': 'Olá! ', \n",
    "                         'Garantia': 'Olá! O produto tem as seguintes garantias: ', \n",
    "                         'Meios de pagamento': 'Olá! Os meios de pagamento que aceitamos são: ', \n",
    "                         'Nota Fiscal': 'Olá! ', \n",
    "                         'Voltagem': 'Olá! '}\n",
    "    \n",
    "    #no caso do produto não ter informação cadastrada pro respectivo intent\n",
    "    if dic_intent == {}:\n",
    "        resposta = \"Olá! Não tenho esta informação cadastrada. Te retornarei novamente mais tarde!\"\n",
    "    else:\n",
    "        #pros intents que tem textinho cadastrado, a resposta é o texto direto, e fim\n",
    "        if \"texto\" in list(dic_intent.keys()):\n",
    "            resposta = respostas_inicio[intent] + dic_intent[\"texto\"]\n",
    "        else:\n",
    "            resposta = respostas_inicio[intent]\n",
    "\n",
    "            if intent == 'Acessórios':\n",
    "\n",
    "                #pra ajustar o ponto final\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    #se tem apenas uma key no dict, eu coloco o ponto final\n",
    "                    #coloco tb o ponto final se for a ultima key do dict (usando a variavel count)\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + str(dic_intent[item]) + \" \" + item + \". \"\n",
    "                    #se tem mais de um acessório, eu os separo por ponto e virgula\n",
    "                    else:\n",
    "                        resposta = resposta + str(dic_intent[item]) + \" \" + item + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Bateria':\n",
    "\n",
    "                #listagem\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Capacidade':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "\n",
    "                        #pro caso de eu ter uma lista de opçoes disponiveis (como pra memoria ram)\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \".\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \";\\n\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Cor':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        #se nao tiver daquela cor disponível\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + \"- \" + item + \" (\" + str(dic_intent[item]) + \" unidade(s))\" + \". \"\n",
    "                    else:\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + \"- \" + item + \" (\" + str(dic_intent[item]) + \" unidade(s))\" + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Dimensão':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "\n",
    "                        #pro caso de eu ter uma lista de opçoes disponiveis (como pra memoria ram)\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \".\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        if type(dic_intent[item]) == list:\n",
    "                            resposta = resposta + \"- \" + item + \": Temos as opções: \" + \"; \".join(dic_intent[item]) + \";\\n\"\n",
    "                        else:\n",
    "                            resposta = resposta + \"- \" + item + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Disponibilidade':\n",
    "\n",
    "                #nessa coluna só vai ter o atributo \"estoque\", com a quantidade em estoque\n",
    "                if dic_intent[\"estoque\"] == 0:\n",
    "                    resposta = resposta + \"Infelizmente, o produto não está mais disponível.\"\n",
    "                else:\n",
    "                    resposta = resposta + \"O produto está disponível! Temos \" + str(dic_intent[\"estoque\"]) + \" unidades em estoque.\"\n",
    "\n",
    "            elif intent == 'Garantia':\n",
    "\n",
    "                resposta = resposta + \"\\n\"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        resposta = resposta + \"- \" + item.replace(\"_\", \" \") + \": \" + str(dic_intent[item]) + \".\"\n",
    "                    else:\n",
    "                        resposta = resposta + \"- \" + item.replace(\"_\", \" \") + \": \" + str(dic_intent[item]) + \";\\n\"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Meios de pagamento':\n",
    "\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        #listo apenas as formas de pagamento disponíveis\n",
    "                        if dic_intent[item] == \"sim\":\n",
    "                            resposta = resposta + item.replace(\"_\", \" \") + \". \"\n",
    "                    else:\n",
    "                        if dic_intent[item] == \"sim\":\n",
    "                            resposta = resposta + item.replace(\"_\", \" \") + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "            elif intent == 'Nota Fiscal':\n",
    "\n",
    "                #so tem esse atributo no dicionario de nota fiscal\n",
    "                if dic_intent[\"nota\"] == \"sim\":\n",
    "                    resposta = resposta + \"O produto será enviado juntamente da Nota Fiscal!\"\n",
    "                elif dic_intent[\"nota\"] == \"nao\":\n",
    "                    resposta = resposta + \"Não emitimos Nota Fiscal.\"\n",
    "\n",
    "            elif intent == 'Voltagem':\n",
    "\n",
    "                resposta = resposta + \"Temos \"\n",
    "                count = 1\n",
    "                for item in list(dic_intent.keys()):\n",
    "\n",
    "                    if len(list(dic_intent.keys())) == 1 or count == len(list(dic_intent.keys())):\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + str(dic_intent[item]) + \" unidades de \" + item + \".\"\n",
    "                    else:\n",
    "                        if dic_intent[item] != 0:\n",
    "                            resposta = resposta + str(dic_intent[item]) + \" unidades de \" + item + \"; \"\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T21:29:07.713842Z",
     "start_time": "2020-05-02T21:29:07.705512Z"
    }
   },
   "outputs": [],
   "source": [
    "#essa é a função que dá a resposta do bot.\n",
    "# seus argumentos são:\n",
    "# - a base de produtos \"base_de_produtos\" (que eu já tenho de ter lido)\n",
    "# - intent, que é o output do modelo\n",
    "# - produto, que é o produto ao qual a pergunta se refere. Isso entra a partir da GUI\n",
    "#dentro desta tem uma que é ainda mais importante, e que eu defini acima, a \"resposta_especificas()\"\n",
    "\n",
    "def respostas_bot(prod = base_de_produtos, intent = \"\", produto = \"\"):\n",
    "\n",
    "    #lista dos produtos construida a partir da base de produtos\n",
    "    lista_de_produtos = [list(ast.literal_eval(item).values())[0] for item in prod[\"Produto\"].tolist()]\n",
    "\n",
    "    #ve qual é o indice de linha do dataframe de produtos correspondentes ao produto a que se refere a pergunta\n",
    "    indice_linha = lista_de_produtos.index(produto)\n",
    "\n",
    "    #dicionario do respectivo produto e do respectivo intent\n",
    "    dic_intent = ast.literal_eval(prod.loc[indice_linha, intent])\n",
    "    \n",
    "    #completa a resposta\n",
    "    resposta_final = resposta_especificas(dic_intent, intent)\n",
    "                 \n",
    "    return resposta_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5: Obot\n",
    "\n",
    "Vamos pegar o melhor modelo dos que foram treinados acima, e usar aqui pra simular o bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T04:17:07.583046Z",
     "start_time": "2020-05-03T04:17:07.572546Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#tem que vir da gui\n",
    "produto = 'Samsung Galaxy J2'\n",
    "\n",
    "usar_nn = False\n",
    "def chat(model, th1 = 2):\n",
    "    \n",
    "    print(\"Digite sua pergunta sobre o produto!\")\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        pergunta = input(\"Pergunta: \")\n",
    "        \n",
    "        if pergunta.lower() == \"sair\":\n",
    "            break\n",
    "        \n",
    "        #faz o pre-processing da pergunta\n",
    "        pergunta = pre_proc(pergunta)\n",
    "            \n",
    "        #eu tenho que fazer o bag da pergunta usando o mesmo cv e corpus de antes, claro\n",
    "        X = cv.transform([pergunta]).toarray()\n",
    "        \n",
    "        #essas são as probabilidades das classes\n",
    "        class_probs = model.predict_proba(X)\n",
    "        \n",
    "        #essa é a chance random\n",
    "        th2 = 1/len(model.classes_)\n",
    "        \n",
    "        \n",
    "        if usar_nn:\n",
    "            #aqui, eu pego quais são as classes que são mais probáveis\n",
    "            #a forma como eu defino é: as classes que tem mais de 1 std de desvio padrao dentro de todas as probs\n",
    "            #pode ser que seja só uma, claro\n",
    "            #mas pode ser que seja mais de uma... se for esse o caso, eu dou output de duas classes\n",
    "            class_max = class_probs[abs(class_probs - np.mean(class_probs)) > 1*np.std(class_probs)]\n",
    "        else:\n",
    "            #aqui, eu pego quais são as classes que são mais probáveis\n",
    "            #a forma como eu defino é: classes que têm probabilidade maior do que th1*th2 da probabilidade máxima\n",
    "            #essas são as classes que o algoritmo mais acha que são as corretas\n",
    "            #pode ser que seja só uma, claro\n",
    "            #mas pode ser que seja mais de uma... se for esse o caso, eu dou output de duas classes\n",
    "            class_max = class_probs[class_probs > class_probs.max() - th1*th2]\n",
    "        \n",
    "        \n",
    "        #a lista de respostas, que depois eu dou um join\n",
    "        resposta = []\n",
    "        nao_sei = True\n",
    "        for prob in class_max:\n",
    "            \n",
    "            if prob > th1*th2:\n",
    "                \n",
    "                y_pred = model.classes_[class_probs.squeeze().tolist().index(prob)]\n",
    "                \n",
    "                #aqui a resposta é formulada\n",
    "                resposta.append(respostas_bot(prod = base_de_produtos, intent = y_pred, produto = produto))\n",
    "\n",
    "                nao_sei = False\n",
    "                \n",
    "        #trasnforma as respostas em strings, separadas por \"\\n\"\n",
    "        resposta = \"\\n\".join(resposta)\n",
    "        \n",
    "        #mas, se não houver nenhuma resposta muito provável...\n",
    "        if nao_sei:\n",
    "            resposta = \"Eu não entendi o que você quis dizer...\" \n",
    "        \n",
    "        print(resposta)\n",
    "        \n",
    "        print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~||~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "\n",
    "#aqui escolhemos qual modelo usar\n",
    "\n",
    "if usar_nn:\n",
    "    #lista com os modelos tradicionais e as redes neurais tb\n",
    "    melhores_modelos_geral = melhores_modelos_fitados_nn + melhores_modelos_fitados\n",
    "else:\n",
    "    melhores_modelos_geral = melhores_modelos_fitados\n",
    "\n",
    "#pega o indice do melhor modelo (o com maior weighted f1)\n",
    "idx = np.array([x[1] for x in melhores_modelos_geral]).argmax()\n",
    "\n",
    "#seleciona o melhor modelo\n",
    "melhor_modelo = melhores_modelos_geral[idx][-1]\n",
    "nome = melhores_modelos_geral[idx][0]\n",
    "\n",
    "print(\"\\n################################################\")\n",
    "print(\"################################################\\n\")\n",
    "print(\"Modelo utilizado:\", nome)\n",
    "print(\"\\n################################################\")\n",
    "print(\"################################################\\n\\n\")\n",
    "\n",
    "#chama a função de chat\n",
    "chat(model=melhor_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 6: Analytcs\n",
    "\n",
    "Aqui apenas gero o df de analytics pra mandar pro Wesley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T00:44:54.040553Z",
     "start_time": "2020-05-03T00:44:53.498385Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"base_teste_perguntas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T00:45:14.112233Z",
     "start_time": "2020-05-03T00:45:06.217408Z"
    }
   },
   "outputs": [],
   "source": [
    "def escolhe_modelo(usar_nn = False):\n",
    "    if usar_nn:\n",
    "        #lista com os modelos tradicionais e as redes neurais tb\n",
    "        melhores_modelos_geral = melhores_modelos_fitados_nn + melhores_modelos_fitados\n",
    "    else:\n",
    "        melhores_modelos_geral = melhores_modelos_fitados\n",
    "\n",
    "    #pega o indice do melhor modelo (o com maior weighted f1)\n",
    "    idx = np.array([x[1] for x in melhores_modelos_geral]).argmax()\n",
    "\n",
    "    #seleciona o melhor modelo\n",
    "    melhor_modelo = melhores_modelos_geral[idx][-1]\n",
    "    nome = melhores_modelos_geral[idx][0]\n",
    "\n",
    "    model = melhor_modelo\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def previsao(x, usar_nn):\n",
    "    \n",
    "    model = escolhe_modelo(usar_nn)\n",
    "\n",
    "    question = pre_proc(x)\n",
    "    X = cv.transform([question]).toarray()\n",
    "\n",
    "    class_probs = model.predict_proba(X)\n",
    "    th2 = 1/len(model.classes_)\n",
    "\n",
    "    if usar_nn:\n",
    "        class_max = class_probs[abs(class_probs - np.mean(class_probs)) > 1*np.std(class_probs)]\n",
    "    else:\n",
    "        class_max = class_probs[class_probs > class_probs.max() - th1*th2]\n",
    "\n",
    "    resposta = []\n",
    "    nao_sei = True\n",
    "    for prob in class_max:\n",
    "        if prob > th1*th2:\n",
    "            y_pred = model.classes_[class_probs.squeeze().tolist().index(prob)]\n",
    "            resposta.append(y_pred)\n",
    "            nao_sei = False\n",
    "            \n",
    "    resposta = \" | \".join(resposta)\n",
    "            \n",
    "    if nao_sei:\n",
    "        resposta = \"Não sei\"\n",
    "\n",
    "    return resposta\n",
    "    \n",
    "    \n",
    "def analysis(row):\n",
    "\n",
    "    real = row[\"intent\"]\n",
    "    previsto = row[\"previsto\"]\n",
    "    \n",
    "    real = real.lower().split(\" | \")\n",
    "    previsto = previsto.lower().split(\" | \")\n",
    "    \n",
    "    score = 0\n",
    "    for item in previsto:\n",
    "        if item in real:\n",
    "            score += 1\n",
    "            \n",
    "    if len(real) > 1:\n",
    "        if score >= len(real)-1:\n",
    "            ans = \"acertou\"\n",
    "        else:\n",
    "            ans = \"errou\"\n",
    "    else:\n",
    "        if score == len(real):\n",
    "            ans = \"acertou\"\n",
    "        else:\n",
    "            ans = \"errou\"\n",
    "        \n",
    "    return ans\n",
    "\n",
    "print(\"\\nCom redes neurais:\")\n",
    "df_com_nn = df_test.copy()\n",
    "df_com_nn[\"previsto\"] = df_com_nn[\"pergunta\"].apply(lambda x: previsao(x, usar_nn=True))\n",
    "df_com_nn[\"analise\"] = df_com_nn.apply(lambda row: analysis(row), axis=1)\n",
    "display(df_com_nn[\"analise\"].value_counts(normalize=True))\n",
    "\n",
    "\n",
    "print(\"\\n########################################\\n\")\n",
    "\n",
    "print(\"\\nSem redes neurais:\")\n",
    "df_sem_nn = df_test.copy()\n",
    "df_sem_nn[\"previsto\"] = df_sem_nn[\"pergunta\"].apply(lambda x: previsao(x, usar_nn=False))\n",
    "df_sem_nn[\"analise\"] = df_sem_nn.apply(lambda row: analysis(row), axis=1)\n",
    "display(df_sem_nn[\"analise\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T23:43:05.258331Z",
     "start_time": "2020-05-02T23:43:05.008522Z"
    }
   },
   "outputs": [],
   "source": [
    "df_com_nn.to_excel(\"base_teste_com_nn.xlsx\")\n",
    "df_sem_nn.to_excel(\"base_teste_sem_nn.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Frequência de intents__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T03:30:13.168884Z",
     "start_time": "2020-05-03T03:30:12.220856Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "data = df_test[\"intent\"].value_counts(normalize=True)\n",
    "\n",
    "sns.barplot(x = data.index.tolist(), y = data.values.tolist())\n",
    "plt.title(\"Frequência relativa de intents na base de teste\")\n",
    "plt.xlabel(\"Intents\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.ylabel(\"Frequência relativa\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T04:15:08.866205Z",
     "start_time": "2020-05-03T04:15:00.853087Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in df_sem_nn[\"intent\"].unique().tolist():\n",
    "    \n",
    "    print(\"Intent:\", item)\n",
    "    \n",
    "    print(\"\\nDe todas as perguntas, as frequencias de acerto e erro são:\")\n",
    "    aux = df_sem_nn[df_sem_nn[\"intent\"] == item]\n",
    "    count = aux[\"analise\"].value_counts(normalize=True)\n",
    "    display(count)\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    g = sns.barplot(x = count.index.tolist(), y = count.values.tolist())\n",
    "    plt.title(\"Frequência de\\nacertos e erros\\ndo intent \" + item)\n",
    "    plt.xlabel(\"Intents\")\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Frequência relativa\")\n",
    "    \n",
    "    ax=g\n",
    "    #annotate axis = seaborn axis\n",
    "    for p in ax.patches:\n",
    "                 ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
    "                     textcoords='offset points')\n",
    "    _ = g.set_ylim(0, 1.2) #To make space for the annotations\n",
    "\n",
    "    \n",
    "    print(\"\\nDe todas as perguntas QUE FORAM RESPONDIDAS (i.e., tirando as que ele respondeu 'Não sei', as frequencias de acerto e erro são:\")\n",
    "    aux = aux[aux[\"previsto\"] != \"Não sei\"]\n",
    "    count = aux[\"analise\"].value_counts(normalize=True)\n",
    "    display(count)\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    g=sns.barplot(x = count.index.tolist(), y = count.values.tolist())\n",
    "    plt.title(\"Frequência de\\nacertos e erros\\ndo intent \" + item + \",\\nentre perguntas\\nefetivamente respondidas\")\n",
    "    plt.xlabel(\"Intents\")\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Frequência relativa\")\n",
    "    \n",
    "    ax=g\n",
    "    #annotate axis = seaborn axis\n",
    "    for p in ax.patches:\n",
    "                 ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                     ha='center', va='center', fontsize=11, color='gray', xytext=(0, 10),\n",
    "                     textcoords='offset points')\n",
    "    _ = g.set_ylim(0, 1.2) #To make space for the annotations\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    print(\"\\n###############################################\")\n",
    "    print(\"###############################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 7: GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T04:17:31.994951Z",
     "start_time": "2020-05-03T04:17:31.989887Z"
    }
   },
   "outputs": [],
   "source": [
    "lista_de_produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T01:03:04.058870Z",
     "start_time": "2020-05-03T00:53:16.233635Z"
    }
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def coletar_produto(produto):\n",
    "    \n",
    "    global product_global\n",
    "    product_global = produto\n",
    "    \n",
    "    foto = tk.PhotoImage(file=\"./imagens/\"+produto+\".png\")\n",
    "    label_imagem = tk.Label(frame_imagem, image=foto)\n",
    "    label_imagem.image = foto\n",
    "    label_imagem.place(relheight=1, relwidth=1)\n",
    "    \n",
    "    \n",
    "################################################\n",
    "\n",
    "def coletar_pergunta(question):\n",
    "    \n",
    "    ans = bot(th1=2, usar_nn=False, pergunta=question, produto=product_global) \n",
    "    \n",
    "    texto_resposta = tk.Label(frame_resposta, bg='white', text=ans, anchor='nw', font=(\"Courier\", 10), justify=\"left\")\n",
    "    texto_resposta.place(relheight=1, relwidth=1)\n",
    "\n",
    "    return pergunta\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "\n",
    "def escolhe_modelo(usar_nn = False):\n",
    "    if usar_nn:\n",
    "        #lista com os modelos tradicionais e as redes neurais tb\n",
    "        melhores_modelos_geral = melhores_modelos_fitados_nn + melhores_modelos_fitados\n",
    "    else:\n",
    "        melhores_modelos_geral = melhores_modelos_fitados\n",
    "\n",
    "    #pega o indice do melhor modelo (o com maior weighted f1)\n",
    "    idx = np.array([x[1] for x in melhores_modelos_geral]).argmax()\n",
    "\n",
    "    #seleciona o melhor modelo\n",
    "    melhor_modelo = melhores_modelos_geral[idx][-1]\n",
    "    nome = melhores_modelos_geral[idx][0]\n",
    "\n",
    "    model = melhor_modelo\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "################################################\n",
    "\n",
    "def bot(th1=2, usar_nn=False, pergunta=\"\", produto=\"\"):\n",
    "\n",
    "    model = escolhe_modelo(usar_nn)\n",
    "    \n",
    "    pergunta_pp = pre_proc(pergunta)\n",
    "\n",
    "    X = cv.transform([pergunta_pp]).toarray()\n",
    "\n",
    "    class_probs = model.predict_proba(X)\n",
    "\n",
    "    th2 = 1/len(model.classes_)\n",
    "\n",
    "    if usar_nn:\n",
    "        class_max = class_probs[abs(class_probs - np.mean(class_probs)) > 1*np.std(class_probs)]\n",
    "    else:\n",
    "        class_max = class_probs[class_probs > class_probs.max() - th1*th2]\n",
    "\n",
    "    resposta = []\n",
    "    nao_sei = True\n",
    "    for prob in class_max:\n",
    "        if prob > th1*th2:\n",
    "            y_pred = model.classes_[class_probs.squeeze().tolist().index(prob)]\n",
    "            resposta.append(respostas_bot(prod = base_de_produtos, intent = y_pred, produto = produto))\n",
    "            nao_sei = False\n",
    "    resposta = \"\\n\".join(resposta)\n",
    "\n",
    "    if nao_sei:\n",
    "        resposta = \"Não entendi a pergunta. Vou direcioná-la ao vendedor, e ele te responderá o mais rápido possível!\" \n",
    "        \n",
    "    return(resposta)\n",
    "\n",
    "\n",
    "################################################3\n",
    "\n",
    "\n",
    "# configuração inicial\n",
    "\n",
    "janela_principal = tk.Tk() # single window\n",
    "janela_principal.title('www.marketplace.com.br')\n",
    "canvas = tk.Canvas(janela_principal, height=700, width=1000) # tamanho da janela ao abrir\n",
    "canvas.pack()\n",
    "\n",
    "# cabeçalhos e bordas\n",
    "\n",
    "frame_cabeçalho = tk.Frame(janela_principal, bg='#ffff33')\n",
    "frame_cabeçalho.place(relwidth=1, relheight=0.2)\n",
    "frame_produto = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_produto.place(relwidth=0.3, relheight=0.05, relx=0.1, rely=0.275)\n",
    "frame_imagem = tk.Frame(janela_principal)\n",
    "frame_imagem.place(relwidth=0.3, relheight=0.22, relx=0.1, rely=0.35)\n",
    "\n",
    "\n",
    "frame_pergunta = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_pergunta.place(relwidth=0.6, relheight=0.1, relx=0.1, rely=0.65)\n",
    "frame_resposta = tk.Frame(janela_principal, bg='#cbcbb3', bd=1)\n",
    "frame_resposta.place(relwidth=0.6, relheight=0.1, relx=0.1, rely=0.85)\n",
    "\n",
    "# botões\n",
    "\n",
    "botao_produto = tk.Button(janela_principal, text='OK', bg='#3385ff', fg='white', command=lambda: coletar_produto(entrada_produto.get()))\n",
    "botao_produto.place(relheight=0.05, relwidth=0.05, relx=0.41, rely=0.275)\n",
    "botao_pergunta = tk.Button(janela_principal, text='Enviar Pergunta', bg='#3385ff', fg='white', command=lambda: coletar_pergunta(entrada_pergunta.get()))\n",
    "botao_pergunta.place(relheight=0.05, relwidth=0.1, rely=0.675, relx=0.723)\n",
    "\n",
    "# labels\n",
    "\n",
    "label_produto = tk.Label(janela_principal, text='Produto', font=40, fg='blue', anchor='w')\n",
    "label_produto.place(relheight=0.05, width=100, relx=0.1, rely=0.22)\n",
    "label_pergunta = tk.Label(janela_principal, text='Pergunte ao vendedor', font=40, fg='blue', anchor='w')\n",
    "label_pergunta.place(relheight=0.05, width=200, relx=0.1, rely=0.595)\n",
    "\n",
    "\n",
    "label_resposta = tk.Label(janela_principal, text='Resposta', font=40, fg='blue', anchor='w')\n",
    "label_resposta.place(relheight=0.05, width=200, relx=0.1, rely=0.795)\n",
    "\n",
    "\n",
    "# entries\n",
    "\n",
    "entrada_produto = tk.Entry(frame_produto, font=40, bg='white')\n",
    "entrada_produto.place(relheight=1, relwidth=1)\n",
    "entrada_pergunta = tk.Entry(frame_pergunta, font=100, bg='white')\n",
    "entrada_pergunta.place(relheight=1, relwidth=1)\n",
    "\n",
    "\n",
    "texto_resposta = tk.Label(frame_resposta, bg='white', text=\"\", anchor='nw', font=(\"Courier\", 10))\n",
    "texto_resposta.place(relheight=1, relwidth=1)\n",
    "\n",
    "\n",
    "janela_principal.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
